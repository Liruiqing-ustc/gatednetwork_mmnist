{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.patches as mpatches\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from random import randint\n",
    "from random import shuffle\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pickle\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "reset_graph()\n",
    "print(\"rdy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ac_sets = [\"0.7\", \"0.8\", \"0.9\"]\n",
    "ic_sets = [\"0.7\", \"0.8\", \"0.9\"]\n",
    "\n",
    "def loadData_TwoModal(ac_per, ic_per,printSize=False):\n",
    "    train_AC = pickle.load(open('data/AC_Training_'+ac_per+'.p', mode='rb'))\n",
    "    valid_AC = pickle.load(open('data/AC_Validation_'+ac_per+'.p', mode='rb'))\n",
    "\n",
    "    train_IC = pickle.load(open('data/IC_Training_'+ic_per+'.p', mode='rb'))\n",
    "    valid_IC = pickle.load(open('data/IC_Validation_'+ic_per+'.p', mode='rb'))\n",
    "    if(printSize):\n",
    "        print(\"Validation samples\",len(valid_AC[0]))\n",
    "        print(\"Training samples\",len(train_AC[0]))\n",
    "    \n",
    "    #Training Set\n",
    "    trainHolder = []\n",
    "    for i in range(len(train_AC[0])):\n",
    "        trainHolder.append([train_AC[0][i],train_IC[0][i],train_AC[1][i]])\n",
    "    #Validation set\n",
    "    validHolder = []    \n",
    "    for i in range(len(valid_AC[0])):\n",
    "        validHolder.append([valid_AC[0][i],valid_IC[0][i],valid_AC[1][i]])\n",
    "    \n",
    "    return trainHolder, validHolder\n",
    "        \n",
    "trainingSet, validationSet = loadData_TwoModal(\"0.9\",\"0.8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training set: 20116\n",
      "Number of samples in validation set: 3549\n",
      "Level of accuracy: 0.7\n",
      "Training accuracy for\n",
      "AC is 73.17%\n",
      "IC is 71.25%\n",
      "Validation accuracy for\n",
      "AC is 70.95%\n",
      "IC is 71.26%\n",
      "\n",
      "Level of accuracy: 0.8\n",
      "Training accuracy for\n",
      "AC is 83.68%\n",
      "IC is 81.26%\n",
      "Validation accuracy for\n",
      "AC is 81.40%\n",
      "IC is 81.09%\n",
      "\n",
      "Level of accuracy: 0.9\n",
      "Training accuracy for\n",
      "AC is 94.58%\n",
      "IC is 91.37%\n",
      "Validation accuracy for\n",
      "AC is 89.41%\n",
      "IC is 90.05%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print info on all classifiers\n",
    "print(\"Number of samples in training set:\",len(trainingSet))\n",
    "print(\"Number of samples in validation set:\",len(validationSet))\n",
    "for acc_level in ac_sets:\n",
    "    trainingSet, validationSet = loadData_TwoModal(acc_level,acc_level)\n",
    "    print(\"Level of accuracy:\",acc_level)\n",
    "    t_ac = 0\n",
    "    t_ic = 0\n",
    "\n",
    "    for i in range(len(trainingSet)):\n",
    "        if(np.argmax(trainingSet[i][0]) == np.argmax(trainingSet[i][2])):\n",
    "            t_ac += 1\n",
    "        if(np.argmax(trainingSet[i][1]) == np.argmax(trainingSet[i][2])):\n",
    "            t_ic += 1\n",
    "\n",
    "    print(\"Training accuracy for\")\n",
    "    print(\"AC is {:.2f}%\".format (t_ac/len(trainingSet)*100))       \n",
    "    print(\"IC is {:.2f}%\".format (t_ic/len(trainingSet)*100))      \n",
    "\n",
    "    v_ac = 0\n",
    "    v_ic = 0\n",
    "\n",
    "    for i in range(len(validationSet)):\n",
    "        if(np.argmax(validationSet[i][0]) == np.argmax(validationSet[i][2])):\n",
    "            v_ac += 1\n",
    "        if(np.argmax(validationSet[i][1]) == np.argmax(validationSet[i][2])):\n",
    "            v_ic += 1\n",
    "    \n",
    "\n",
    "    print(\"Validation accuracy for\")\n",
    "    print(\"AC is {:.2f}%\".format (v_ac/len(validationSet)*100))\n",
    "    print(\"IC is {:.2f}%\".format (v_ic/len(validationSet)*100))  \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set agreement of AC/IC 0.7 0.7 : 0.5142\n",
      "Validation set agreement of AC/IC 0.7 0.7 : 0.5052\n",
      "\n",
      "Training set agreement of AC/IC 0.7 0.8 : 0.5795\n",
      "Validation set agreement of AC/IC 0.7 0.8 : 0.5680\n",
      "\n",
      "Training set agreement of AC/IC 0.7 0.9 : 0.6804\n",
      "Validation set agreement of AC/IC 0.7 0.9 : 0.6500\n",
      "\n",
      "Training set agreement of AC/IC 0.8 0.7 : 0.6056\n",
      "Validation set agreement of AC/IC 0.8 0.7 : 0.5940\n",
      "\n",
      "Training set agreement of AC/IC 0.8 0.8 : 0.6761\n",
      "Validation set agreement of AC/IC 0.8 0.8 : 0.6624\n",
      "\n",
      "Training set agreement of AC/IC 0.8 0.9 : 0.7804\n",
      "Validation set agreement of AC/IC 0.8 0.9 : 0.7447\n",
      "\n",
      "Training set agreement of AC/IC 0.9 0.7 : 0.6739\n",
      "Validation set agreement of AC/IC 0.9 0.7 : 0.6475\n",
      "\n",
      "Training set agreement of AC/IC 0.9 0.8 : 0.7552\n",
      "Validation set agreement of AC/IC 0.9 0.8 : 0.7202\n",
      "\n",
      "Training set agreement of AC/IC 0.9 0.9 : 0.8803\n",
      "Validation set agreement of AC/IC 0.9 0.9 : 0.8166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check the agreement factor between components\n",
    "for ac in ac_sets:\n",
    "    for ic in ic_sets:\n",
    "        trainingSet, validationSet = loadData_TwoModal(ac,ic)\n",
    "        train_agreement_ac_ic = 0\n",
    "\n",
    "        for i in range(len(trainingSet)):\n",
    "            if(np.argmax(trainingSet[i][0]) == np.argmax(trainingSet[i][1])):\n",
    "                train_agreement_ac_ic += 1\n",
    "\n",
    "\n",
    "        print(\"Training set agreement of AC/IC\",ac,ic,\": %.4f\" % (train_agreement_ac_ic/len(trainingSet))) \n",
    "\n",
    "        valid_agreement_ac_ic = 0\n",
    "\n",
    "        for i in range(len(validationSet)):\n",
    "            if(np.argmax(validationSet[i][0]) == np.argmax(validationSet[i][1])):\n",
    "                valid_agreement_ac_ic += 1\n",
    "\n",
    "        print(\"Validation set agreement of AC/IC\",ac,ic,\": %.4f\" % (valid_agreement_ac_ic/len(validationSet))) \n",
    "        print()\n",
    "\n",
    "### TODO: Check this, something wrong here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation % AC/IC at 0.7 / 0.7 is : 92.53\n",
      "Validation % AC/IC at 0.7 / 0.8 is : 94.70\n",
      "Validation % AC/IC at 0.7 / 0.9 is : 97.44\n",
      "Validation % AC/IC at 0.8 / 0.7 is : 94.20\n",
      "Validation % AC/IC at 0.8 / 0.8 is : 95.52\n",
      "Validation % AC/IC at 0.8 / 0.9 is : 98.28\n",
      "Validation % AC/IC at 0.9 / 0.7 is : 96.62\n",
      "Validation % AC/IC at 0.9 / 0.8 is : 97.63\n",
      "Validation % AC/IC at 0.9 / 0.9 is : 99.07\n"
     ]
    }
   ],
   "source": [
    "# Display the percentage of correcly classified samples by either AC or IC\n",
    "\n",
    "for acc_level_a in ac_sets:\n",
    "    for acc_level_b in ic_sets:\n",
    "        \n",
    "        # Set to false to print out in table for excel format\n",
    "        displayNotebook = True\n",
    "\n",
    "        # AC / IC AND AC/TC\n",
    "        trainingSet, validationSet = loadData_TwoModal(acc_level_a,acc_level_b)\n",
    "\n",
    "        trainKnowledge = 0\n",
    "        validKnowledge = 0\n",
    "\n",
    "        for i in range(len(trainingSet)):\n",
    "            if(np.argmax(trainingSet[i][0]) == np.argmax(trainingSet[i][2])\n",
    "              or\n",
    "              np.argmax(trainingSet[i][1]) == np.argmax(trainingSet[i][2])\n",
    "              ):\n",
    "                trainKnowledge += 1\n",
    "\n",
    "\n",
    "        for i in range(len(validationSet)):\n",
    "            if(np.argmax(validationSet[i][0]) == np.argmax(validationSet[i][2])\n",
    "               or\n",
    "               np.argmax(validationSet[i][1]) == np.argmax(validationSet[i][2])\n",
    "              ):\n",
    "                    validKnowledge += 1\n",
    "\n",
    "        if(displayNotebook):\n",
    "            print(\"Validation % AC/IC at\",acc_level_a,\"/\",acc_level_b,\"is : {:.2f}\".format (validKnowledge/len(validationSet)*100)) \n",
    "        else:\n",
    "            a=(\"{:.2f}\".format (train_agreement_ac_ic/len(trainingSet)*100)) \n",
    "            b=(\" {:.2f}\".format (valid_agreement_ic_tc/len(validationSet)*100)) \n",
    "            print(a+b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training of AC IC 0.9 0.9\n",
      "Max accuracy at epoch 981  was: 0.848408\n",
      "GN_10 recall score: ['94.86%', '93.71%', '0.00%', '93.22%', '95.24%', '93.87%', '93.54%', '91.08%', '95.72%', '94.63%']\n",
      "done, predict valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy at epoch 831  was: 0.975204\n",
      "GN_50 recall score: ['99.09%', '98.43%', '98.26%', '96.48%', '97.76%', '97.87%', '96.91%', '95.68%', '97.59%', '97.46%']\n",
      "done, predict valid\n"
     ]
    }
   ],
   "source": [
    "### RUN ALL EXPERIMENTS WITH GATING NETWORK on highest accuracy\n",
    "ac = \"0.9\"\n",
    "ic = \"0.9\"\n",
    "# Measure recall score for GN_10 and GN_50\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "trainingSet, validationSet = loadData_TwoModal(ac,ic)\n",
    "print(\"Start Training of AC IC\",ac,ic)\n",
    "\n",
    "weightSize_check = [10,50] # 50\n",
    "for w in weightSize_check:\n",
    "    reset_graph()\n",
    "\n",
    "    pkeep = tf.placeholder(tf.float32, shape=[])\n",
    "    weightSize = w\n",
    "    # 10 features\n",
    "    x1 = [row[0] for row in trainingSet] \n",
    "    x2 = [row[1] for row in trainingSet] \n",
    "    y =  [row[2] for row in trainingSet] \n",
    "\n",
    "    x1_test = [row[0] for row in validationSet] \n",
    "    x2_test = [row[1] for row in validationSet] \n",
    "    y_test =  [row[2] for row in validationSet] \n",
    "\n",
    "    x1_input = tf.placeholder(tf.float32, [None, 10])\n",
    "    x2_input = tf.placeholder(tf.float32, [None, 10])\n",
    "    y_label = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "    # Other method according to paper\n",
    "    o_Wv = tf.Variable(tf.random_uniform([ 10, weightSize],  minval=-0.2,maxval=0.2))\n",
    "    o_Wt = tf.Variable(tf.random_uniform([ 10, weightSize],  minval=-0.2,maxval=0.2))\n",
    "    o_Wz = tf.Variable(tf.random_uniform([ 20, weightSize],  minval=-0.2,maxval=0.2))\n",
    "\n",
    "    o_hv = tf.nn.tanh(tf.matmul(x1_input, o_Wv))\n",
    "    o_ht = tf.nn.tanh(tf.matmul(x2_input, o_Wt))\n",
    "\n",
    "    ddd = tf.concat((x1_input,x2_input), axis=1)\n",
    "    o_z = tf.nn.relu(tf.matmul(ddd, o_Wz))\n",
    "\n",
    "    if(weightSize == 10):\n",
    "        o_h = tf.nn.softmax(tf.multiply(o_z, o_hv) + tf.multiply((1-o_z), o_ht))\n",
    "    else:\n",
    "        o_h_temp = tf.multiply(o_z, o_hv) + tf.multiply((1-o_z), o_ht)\n",
    "        W1  = tf.Variable(tf.random_uniform([50, 128],  minval=-0.2,maxval=0.2))\n",
    "        B1 =  tf.Variable(tf.random_normal([128], mean=0.1,stddev=.1))\n",
    "        W2  = tf.Variable(tf.random_uniform([128, 64],  minval=-0.2,maxval=0.2))\n",
    "        B2 =  tf.Variable(tf.random_normal([64], mean=0.1,stddev=.1))\n",
    "        W3  = tf.Variable(tf.random_uniform([64, 10],  minval=-0.2,maxval=0.2))\n",
    "        B3 =  tf.Variable(tf.random_normal([10], mean=0.1,stddev=.1))\n",
    "\n",
    "        L1 =  tf.nn.relu(tf.add(tf.matmul(o_h_temp, W1), B1))\n",
    "        L1_hat_dropout = tf.nn.dropout(L1,pkeep)\n",
    "\n",
    "        L2 =  tf.nn.relu(tf.add(tf.matmul(L1_hat_dropout, W2), B2))\n",
    "        L2_hat_dropout = tf.nn.dropout(L2,pkeep)\n",
    "\n",
    "        o_h =  tf.nn.softmax(tf.add(tf.matmul(L2_hat_dropout, W3), B3))\n",
    "\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=o_h, labels=y_label)\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy) * 100\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "    correct_pred = tf.equal(tf.argmax(o_h, 1), tf.argmax(y_label, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    epochs = 1000\n",
    "\n",
    "    t_acc = []\n",
    "    v_acc = []\n",
    "\n",
    "    gn_t_pred = []\n",
    "    gn_v_pred = []\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        maxEpoch, maxValid = 0,0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            #currValidLoss, currValidAcc = sess.run([cost,accuracy], feed_dict={x: batch_x, y: batch_y, keep_prob: 1.})\n",
    "            _, tacc = sess.run([train_step, accuracy], feed_dict={x1_input: x1, x2_input: x2, y_label: y, pkeep:0.5})\n",
    "            t_acc.append(tacc)\n",
    "            #print(\"epoch\",epoch)\n",
    "            #print(\"train acc\", tacc)\n",
    "\n",
    "            vacc = sess.run(accuracy, feed_dict={x1_input: x1_test, x2_input: x2_test, y_label: y_test,  pkeep:1})\n",
    "            v_acc.append(vacc)\n",
    "            #print(\"valid acc\", vacc)\n",
    "            if(vacc >maxValid):\n",
    "                maxEpoch = epoch\n",
    "                maxValid = vacc\n",
    "                gn_v_pred = sess.run(o_h, feed_dict={x1_input: x1_test, x2_input: x2_test, y_label: y_test, pkeep:1})\n",
    "\n",
    "\n",
    "        print(\"Max accuracy at epoch\",maxEpoch,\" was:\",maxValid)\n",
    "        placehold = [0] * len(gn_v_pred)\n",
    "        yyy = [np.argmax(row[2]) for row in validationSet]\n",
    "        for i in range(len(validationSet)):\n",
    "            arr = np.argmax(gn_v_pred[i])\n",
    "            placehold[i] = arr\n",
    "\n",
    "        precision, recall, fscore, support = score(yyy, placehold)\n",
    "        arr_recall = ['{:.2f}%'.format(i*100) for i in recall]\n",
    "\n",
    "        print('GN_'+str(w)+ ' recall score:',arr_recall)\n",
    "        #tt = sess.run(o_h, feed_dict={x1_input: x1, x2_input: x2, y_label: y, pkeep:1})\n",
    "        #vv = sess.run(o_h, feed_dict={x1_input: x1_test, x2_input: x2_test, y_label: y_test, pkeep:1})\n",
    "        #gn_t_pred = tt\n",
    "        #gn_v_pred = vv\n",
    "        print(\"done, predict valid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training of AC IC 0.7 0.7\n",
      "Max accuracy at epoch 968  was: 0.932375\n",
      "Start Training of AC IC 0.7 0.8\n",
      "Max accuracy at epoch 792  was: 0.948154\n",
      "Start Training of AC IC 0.7 0.9\n",
      "Max accuracy at epoch 753  was: 0.963652\n",
      "Start Training of AC IC 0.8 0.7\n",
      "Max accuracy at epoch 973  was: 0.948436\n",
      "Start Training of AC IC 0.8 0.8\n",
      "Max accuracy at epoch 968  was: 0.959707\n",
      "Start Training of AC IC 0.8 0.9\n",
      "Max accuracy at epoch 670  was: 0.972668\n",
      "Start Training of AC IC 0.9 0.7\n",
      "Max accuracy at epoch 903  was: 0.956044\n",
      "Start Training of AC IC 0.9 0.8\n",
      "Max accuracy at epoch 864  was: 0.965624\n",
      "Start Training of AC IC 0.9 0.9\n",
      "Max accuracy at epoch 857  was: 0.974923\n"
     ]
    }
   ],
   "source": [
    "### RUN ALL EXPERIMENTS WITH GN_50\n",
    "for ac in ac_sets:\n",
    "    for ic in ic_sets:\n",
    "        trainingSet, validationSet = loadData_TwoModal(ac,ic)\n",
    "        print(\"Start Training of AC IC\",ac,ic)\n",
    "        reset_graph()\n",
    "\n",
    "        # Change from 10 to 50 here\n",
    "        weightSize = 50\n",
    "        pkeep = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "        # 10 features\n",
    "        x1 = [row[0] for row in trainingSet] \n",
    "        x2 = [row[1] for row in trainingSet] \n",
    "        y =  [row[2] for row in trainingSet] \n",
    "\n",
    "        x1_test = [row[0] for row in validationSet] \n",
    "        x2_test = [row[1] for row in validationSet] \n",
    "        y_test =  [row[2] for row in validationSet] \n",
    "\n",
    "        x1_input = tf.placeholder(tf.float32, [None, 10])\n",
    "        x2_input = tf.placeholder(tf.float32, [None, 10])\n",
    "        y_label = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "        # Other method according to paper\n",
    "        o_Wv = tf.Variable(tf.random_uniform([ 10, weightSize],  minval=-0.2,maxval=0.2))\n",
    "        o_Wt = tf.Variable(tf.random_uniform([ 10, weightSize],  minval=-0.2,maxval=0.2))\n",
    "        o_Wz = tf.Variable(tf.random_uniform([ 20, weightSize],  minval=-0.2,maxval=0.2))\n",
    "\n",
    "        o_hv = tf.nn.tanh(tf.matmul(x1_input, o_Wv))\n",
    "        o_ht = tf.nn.tanh(tf.matmul(x2_input, o_Wt))\n",
    "\n",
    "        ddd = tf.concat((x1_input,x2_input), axis=1)\n",
    "        o_z = tf.nn.relu(tf.matmul(ddd, o_Wz))\n",
    "\n",
    "        if(weightSize == 10):\n",
    "            o_h = tf.nn.softmax(tf.multiply(o_z, o_hv) + tf.multiply((1-o_z), o_ht))\n",
    "        else:\n",
    "            o_h_temp = tf.multiply(o_z, o_hv) + tf.multiply((1-o_z), o_ht)\n",
    "            W1  = tf.Variable(tf.random_uniform([50, 128],  minval=-0.2,maxval=0.2))\n",
    "            B1 =  tf.Variable(tf.random_normal([128], mean=0.1,stddev=.1))\n",
    "            W2  = tf.Variable(tf.random_uniform([128, 64],  minval=-0.2,maxval=0.2))\n",
    "            B2 =  tf.Variable(tf.random_normal([64], mean=0.1,stddev=.1))\n",
    "            W3  = tf.Variable(tf.random_uniform([64, 10],  minval=-0.2,maxval=0.2))\n",
    "            B3 =  tf.Variable(tf.random_normal([10], mean=0.1,stddev=.1))\n",
    "\n",
    "            L1 =  tf.nn.relu(tf.add(tf.matmul(o_h_temp, W1), B1))\n",
    "            L1_hat_dropout = tf.nn.dropout(L1,pkeep)\n",
    "            \n",
    "            L2 =  tf.nn.relu(tf.add(tf.matmul(L1_hat_dropout, W2), B2))\n",
    "            L2_hat_dropout = tf.nn.dropout(L2,pkeep)\n",
    "\n",
    "            o_h =  tf.nn.softmax(tf.add(tf.matmul(L2_hat_dropout, W3), B3))\n",
    "\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=o_h, labels=y_label)\n",
    "        cross_entropy = tf.reduce_mean(cross_entropy) * 100\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "        correct_pred = tf.equal(tf.argmax(o_h, 1), tf.argmax(y_label, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        epochs = 1000\n",
    "\n",
    "        t_acc = []\n",
    "        v_acc = []\n",
    "\n",
    "        gn_t_pred = []\n",
    "        gn_v_pred = []\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            maxEpoch, maxValid = 0,0\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "\n",
    "                #currValidLoss, currValidAcc = sess.run([cost,accuracy], feed_dict={x: batch_x, y: batch_y, keep_prob: 1.})\n",
    "                _, tacc = sess.run([train_step, accuracy], feed_dict={x1_input: x1, x2_input: x2, y_label: y, pkeep:0.5})\n",
    "                t_acc.append(tacc)\n",
    "                #print(\"epoch\",epoch)\n",
    "                #print(\"train acc\", tacc)\n",
    "\n",
    "                vacc = sess.run(accuracy, feed_dict={x1_input: x1_test, x2_input: x2_test, y_label: y_test,  pkeep:1})\n",
    "                v_acc.append(vacc)\n",
    "                #print(\"valid acc\", vacc)\n",
    "                if(vacc >maxValid):\n",
    "                    maxEpoch = epoch\n",
    "                    maxValid = vacc\n",
    "\n",
    "            print(\"Max accuracy at epoch\",maxEpoch,\" was:\",maxValid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Training MLP of AC,IC, 0.7 0.7  Accuracy at max epoch 972 : 92.3077\n",
      "Done Training MLP of AC,IC, 0.7 0.8  Accuracy at max epoch 989 : 93.7447\n",
      "Done Training MLP of AC,IC, 0.7 0.9  Accuracy at max epoch 856 : 96.0271\n",
      "Done Training MLP of AC,IC, 0.8 0.7  Accuracy at max epoch 797 : 94.3083\n",
      "Done Training MLP of AC,IC, 0.8 0.8  Accuracy at max epoch 760 : 95.8862\n",
      "Done Training MLP of AC,IC, 0.8 0.9  Accuracy at max epoch 182 : 97.2105\n",
      "Done Training MLP of AC,IC, 0.9 0.7  Accuracy at max epoch 912 : 95.8298\n",
      "Done Training MLP of AC,IC, 0.9 0.8  Accuracy at max epoch 602 : 96.7597\n",
      "Done Training MLP of AC,IC, 0.9 0.9  Accuracy at max epoch 553 : 97.9431\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "# TRAIN THE MLP\n",
    "\n",
    "for ac in ac_sets:\n",
    "    for ic in ic_sets:\n",
    "        trainingSet, validationSet = loadData_TwoModal(ac,ic)\n",
    "        \n",
    "        x1_10_mlp = [row[0] for row in trainingSet]\n",
    "        x2_10_mlp = [row[1] for row in trainingSet]\n",
    "        y_mlp =     [row[2] for row in trainingSet]  \n",
    "\n",
    "        xt_10_mlp_concat = np.concatenate((x1_10_mlp, x2_10_mlp),axis=1)\n",
    "\n",
    "        x1_10_mlp_test = [row[0] for row in validationSet]\n",
    "        x2_10_mlp_test = [row[1] for row in validationSet]\n",
    "        y_mlp_test =     [row[2] for row in validationSet]\n",
    "\n",
    "        xv_10_mlp_concat_test = np.concatenate((x1_10_mlp_test, x2_10_mlp_test),axis=1)\n",
    "        reset_graph()\n",
    "\n",
    "        X = tf.placeholder(tf.float32, [None, 20])\n",
    "        Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "        aLearningRate = tf.placeholder(tf.float32, shape=[])\n",
    "        max_learning_rate = 0.005\n",
    "        min_learning_rate = 0.0001\n",
    "        decay_speed = 2000.0\n",
    "\n",
    "        pkeep = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "        W1  = tf.Variable(tf.random_uniform([20, 40],  minval=-0.2,maxval=0.2))\n",
    "        B1 =  tf.Variable(tf.random_normal([40], mean=0.1,stddev=.1))\n",
    "\n",
    "        W2 = tf.Variable(tf.random_uniform([40, 25],  minval=-0.2,maxval=0.2))\n",
    "        B2 = tf.Variable(tf.random_normal([25], mean=0.1,stddev=.1))\n",
    "\n",
    "        W3 = tf.Variable(tf.random_uniform([25, 10],  minval=-0.2,maxval=0.2))\n",
    "        B3 = tf.Variable(tf.random_normal([10], mean=0.1,stddev=.1))\n",
    "\n",
    "\n",
    "        Y1_hat =tf.nn.relu(tf.add(tf.matmul(X, W1), B1))\n",
    "        Y1_hat_dropout = tf.nn.dropout(Y1_hat,pkeep)\n",
    "\n",
    "        Y2_hat =  tf.nn.relu(tf.add(tf.matmul(Y1_hat_dropout, W2), B2))\n",
    "        Y2_hat_dropout = tf.nn.dropout(Y2_hat,pkeep)\n",
    "\n",
    "        Y3_hat =  tf.nn.relu(tf.add(tf.matmul(Y2_hat_dropout, W3), B3))\n",
    "        Y_hat = tf.nn.softmax(Y3_hat)\n",
    "\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Y_hat, labels=Y)\n",
    "        cross_entropy = tf.reduce_mean(cross_entropy) * 100\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=aLearningRate)\n",
    "        train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "        correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_hat, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        n_epochs = 1000\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            dropout = 0.5\n",
    "            maxEpoch, maxValid = 0,0\n",
    "\n",
    "            # train\n",
    "            for epoch in range(n_epochs):\n",
    "                learning_rate = min_learning_rate+(max_learning_rate - min_learning_rate) * math.exp((-1*epoch)/2000)\n",
    "                sess.run(train_step, feed_dict={X: xt_10_mlp_concat, Y: y_mlp, aLearningRate: learning_rate, pkeep:dropout})\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "                acc = sess.run(accuracy, feed_dict={X: xv_10_mlp_concat_test, Y: y_mlp_test, pkeep:1})\n",
    "                if(acc >maxValid):\n",
    "                    maxEpoch = epoch\n",
    "                    maxValid = acc\n",
    "            # validate\n",
    "            print(\"Done Training MLP of AC,IC,\",ac,ic,\" Accuracy at max epoch\",maxEpoch,\": %.4f\" % (100*maxValid))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Test SVM for highest accuracy\\ntrainingSet, validationSet = loadData_TwoModal(\"0.9\",\"0.9\")\\nx1_10_svm = [row[0] for row in trainingSet]\\nx2_10_svm = [row[1] for row in trainingSet]\\ny_svm =     [np.argmax(row[2]) for row in trainingSet]  \\nxt_10_svm_concat = np.concatenate((x1_10_svm, x2_10_svm),axis=1)\\n\\nx1_10_svm_test = [row[0] for row in validationSet]\\nx2_10_svm_test = [row[1] for row in validationSet]\\ny_svm_test =     [np.argmax(row[2]) for row in validationSet]\\nxv_10_svm_concat_test = np.concatenate((x1_10_svm_test, x2_10_svm_test),axis=1)\\n\\nfrom sklearn import svm, grid_search\\nfrom sklearn.model_selection import GridSearchCV\\ndef svc_param_selection(X, y, nfolds):\\n    Cs = [0.001, 0.01, 0.1, 1, 10]\\n    gammas = [0.001, 0.01, 0.1, 1]\\n    param_grid = {\\'C\\': Cs, \\'gamma\\' : gammas}\\n    grid_search = GridSearchCV(svm.SVC(kernel=\\'linear\\'), param_grid, cv=nfolds)\\n    grid_search.fit(X, y)\\n    grid_search.best_params_\\n    return grid_search.best_params_\\n\\na = svc_param_selection(xt_10_svm_concat,y_svm,5)\\nprint(a)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Do grid search for CS and gammas\n",
    "\"\"\"\n",
    "# Test SVM for highest accuracy\n",
    "trainingSet, validationSet = loadData_TwoModal(\"0.9\",\"0.9\")\n",
    "x1_10_svm = [row[0] for row in trainingSet]\n",
    "x2_10_svm = [row[1] for row in trainingSet]\n",
    "y_svm =     [np.argmax(row[2]) for row in trainingSet]  \n",
    "xt_10_svm_concat = np.concatenate((x1_10_svm, x2_10_svm),axis=1)\n",
    "\n",
    "x1_10_svm_test = [row[0] for row in validationSet]\n",
    "x2_10_svm_test = [row[1] for row in validationSet]\n",
    "y_svm_test =     [np.argmax(row[2]) for row in validationSet]\n",
    "xv_10_svm_concat_test = np.concatenate((x1_10_svm_test, x2_10_svm_test),axis=1)\n",
    "\n",
    "from sklearn import svm, grid_search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def svc_param_selection(X, y, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='linear'), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "\n",
    "a = svc_param_selection(xt_10_svm_concat,y_svm,5)\n",
    "print(a)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Training SVM of AC,IC 0.7 0.7  Accuracy: 92.59\n",
      "Done Training SVM of AC,IC 0.7 0.8  Accuracy: 94.39\n",
      "Done Training SVM of AC,IC 0.7 0.9  Accuracy: 96.20\n",
      "Done Training SVM of AC,IC 0.8 0.7  Accuracy: 94.31\n",
      "Done Training SVM of AC,IC 0.8 0.8  Accuracy: 95.86\n",
      "Done Training SVM of AC,IC 0.8 0.9  Accuracy: 97.32\n",
      "Done Training SVM of AC,IC 0.9 0.7  Accuracy: 95.60\n",
      "Done Training SVM of AC,IC 0.9 0.8  Accuracy: 96.31\n",
      "Done Training SVM of AC,IC 0.9 0.9  Accuracy: 97.52\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE SVM\n",
    "\n",
    "for ac in ac_sets:\n",
    "    for ic in ic_sets:\n",
    "        trainingSet, validationSet = loadData_TwoModal(ac,ic)\n",
    "        x1_10_svm = [row[0] for row in trainingSet]\n",
    "        x2_10_svm = [row[1] for row in trainingSet]\n",
    "        y_svm =     [np.argmax(row[2]) for row in trainingSet]  \n",
    "        xt_10_svm_concat = np.concatenate((x1_10_svm, x2_10_svm),axis=1)\n",
    "\n",
    "        x1_10_svm_test = [row[0] for row in validationSet]\n",
    "        x2_10_svm_test = [row[1] for row in validationSet]\n",
    "        y_svm_test =     [np.argmax(row[2]) for row in validationSet]\n",
    "        xv_10_svm_concat_test = np.concatenate((x1_10_svm_test, x2_10_svm_test),axis=1)\n",
    "\n",
    "        #print(\"Start Training of AC IC\",ac,ic)\n",
    "        \n",
    "        model_10_svc = svm.SVC(probability=True, kernel='linear', gamma= 0.001, C= 0.1, decision_function_shape='ovo')\n",
    "        model_10_svc.fit(xt_10_svm_concat, y_svm)\n",
    "        ty_pred_10_svc = model_10_svc.predict(xt_10_svm_concat)\n",
    "        y_pred_10_svc = model_10_svc.predict(xv_10_svm_concat_test)\n",
    "\n",
    "        tacc_10_svc = accuracy_score(y_svm, ty_pred_10_svc)\n",
    "        #print(\"Training accuracy: {:.4f}\".format(tacc_10_svc))\n",
    "\n",
    "        vacc_10_svc = accuracy_score(y_svm_test, y_pred_10_svc)\n",
    "        #print(\"Validation accuracy: {:.4f}\".format(vacc_10_svc))\n",
    "        print(\"Done Training SVM of AC,IC\",ac,ic,\" Accuracy: {:.2f}\".format(vacc_10_svc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct samples: 3461 ( 0.9752042828965906 )\n",
      "Incorrect samples: 88 ( 0.02479571710340941 )\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# See uncorrect labels at 0.9 0.9 for GN_50\n",
    "correct_samples = []\n",
    "incorrect_samples = []\n",
    "y_label = [np.argmax(row[2]) for row in validationSet]\n",
    "for i in range(len(validationSet)):\n",
    "    if(y_label[i] != placehold[i]):\n",
    "        incorrect_samples.append([i,placehold[i]])\n",
    "    else: \n",
    "        correct_samples.append([i,placehold[i]])\n",
    "        \n",
    "print(\"Correct samples:\",len(correct_samples),\"(\", (len(correct_samples) / len(validationSet)),\")\")\n",
    "print(\"Incorrect samples:\",len(incorrect_samples),\"(\",(len(incorrect_samples) / len(validationSet)),\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58, 4]\n"
     ]
    }
   ],
   "source": [
    "print(incorrect_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# FUNCTION TO DISPLAY A SAMPLE OF AUDIO, IMAGE, AND TEXTUAL DESCRIPTION\n",
    "\n",
    "Display_Training_Data = pickle.load(open('data/Training_MMNIST.p', mode='rb'))\n",
    "Display_Validation_Data = pickle.load(open('data/Validation_MMNIST.p', mode='rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing sample number 58\n",
      "Prediction - GN 4 AC 4 IC 0\n",
      "Real label 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADyZJREFUeJzt3X+Q1PV9x/HXm+OAKCSBkN4QQIEWY6y2aC8YkGk1GKOU\nBBMrA5MmpCUhsZGJjtpY02mcdjJxTAxjxsQUlQkaQ2xqCExq7CBtQmwschijEjRSBhXCDxOsohY8\nuHf/uC+ZE+/72b3d7+53j/fzMXNzu9/397vf9yy87ru7n/1+P+buAhDPkLIbAFAOwg8ERfiBoAg/\nEBThB4Ii/EBQhB8IivADQRF+IKihzdzZMBvuI3RiM3cJhHJQr+g1P2TVrFtX+M3sQkk3S2qTdLu7\n35Baf4RO1Nk2u55dAkjY6OurXrfml/1m1ibp65IuknSapIVmdlqtjweguep5zz9d0jZ33+7ur0n6\nrqR5xbQFoNHqCf94Sc/1ub8zW/Y6ZrbEzLrMrKtbh+rYHYAiNfzTfndf7u6d7t7ZruGN3h2AKtUT\n/l2SJva5PyFbBmAQqCf8myRNNbPJZjZM0gJJa4tpC0Cj1TzU5+6HzexySf+u3qG+Fe6+pbDOADRU\nXeP87n6fpPsK6gVAE/H1XiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q\nFOEHgmrqpbvRep6+86x0ffbtyfq5l1+WrJ+weuOAe0JzcOQHgiL8QFCEHwiK8ANBEX4gKMIPBEX4\ngaAY5z/O/fYTM5L1zefdlKz3VJhladf56f1PXZ2uozwc+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4g\nqLrG+c1sh6QDko5IOuzunUU0hYGxM/8wt/aDf/hyctuRQ95U175//9RfJ+s2PP97An7oUF37Rn2K\n+JLPee7+mwIeB0AT8bIfCKre8LukB8xss5ktKaIhAM1R78v+We6+y8x+T9I6M3vS3Tf0XSH7o7BE\nkkbohDp3B6AodR353X1X9nufpNWSpvezznJ373T3zvYKJ4kAaJ6aw29mJ5rZqKO3JV0g6YmiGgPQ\nWPW87O+QtNrMjj7Od9z9/kK6AtBwNYff3bdL+uMCe0GOg3Pf8G7qdUZcmT/W3tFW3zh+JfefuiZZ\nv+PRCbm1bm9Lbnvryg8k62/bcjhZH/HDh5P16BjqA4Ii/EBQhB8IivADQRF+ICjCDwRl7t60nb3Z\nxvjZNrtp+2sVQ0+emKy/+M/tyfqKd92VrE8eOmLAPRVliCxZ71Hj/n9t606fEvyJJ/8yt/bWT76W\n3Pbwcztr6qlsG329XvL96X+UDEd+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKKboLcOTcs5L10V/c\nkaz/YNK6CnuofRx/1YGOZP2f1lyarHc83JPeQYUR5b3T848vfz57U3Lbz739x8n6H7SnT1f+8Rnf\ny619ZNUFyW1fWTA+WT+8c1eyPhhw5AeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoDifv0qHLnp3bu2O\nby5LbnvS0MZePvtHr47KrX1z7pzktkee2lZ0O4V5+dKzk/WOpduT9fkdXbm1S0amJ5ZetOP8ZP3F\nS4Yl64f37E3WG4Xz+QFURPiBoAg/EBThB4Ii/EBQhB8IivADQVU8n9/MVkiaK2mfu5+eLRsj6R5J\nkyTtkDTf3V9oXJvl2/XR7tza8KpGVWv3Ys/BZP3qey/PrU1+6qGi22makd/bmKy/kn+6viTprgkz\nc2tr73k1ue3KSQ8k64tXn5es752RLLeEao7835J04THLrpW03t2nSlqf3QcwiFQMv7tvkLT/mMXz\nJK3Mbq+UdHHBfQFosFrf83e4++7s9h5J6WtFAWg5dX/g570nB+SeIGBmS8ysy8y6upWeWw1A89Qa\n/r1mNk6Sst/78lZ09+Xu3unune0aXuPuABSt1vCvlbQou71I0ppi2gHQLBXDb2arJD0k6Z1mttPM\nFku6QdL7zOxpSedn9wEMIhXH+d19YU5pcJ6YX6P7z7klt9bRVt/5+oc8/zsEkjTz21cn65P/bvCO\n5TdS6tr6v73yjPTGq9Plv3/Hj5L1pTon/QAtgG/4AUERfiAowg8ERfiBoAg/EBThB4Jiiu4mOOXf\nPp2sj/55+p9h8q0M5RXt2Tn5lzuPgiM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFOH+V/ubkWTVv\ne4o2FdgJitAx89fJeru1JesXL78mWZ+onw24p2bjyA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTHO\nj+NWz/qJubU171yV3LbbhxXdTsvhyA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQVUc5zezFZLmStrn\n7qdny66X9ElJz2erXefu9zWqSaA/z35hZrL+01O+nFs7wUYkt5375LxkfdLXtyTrR5LV1lDNkf9b\nki7sZ/kyd5+W/RB8YJCpGH533yBpfxN6AdBE9bznX2pmj5nZCjMbXVhHAJqi1vDfKmmKpGmSdku6\nKW9FM1tiZl1m1tWtQzXuDkDRagq/u+919yPu3iPpNknTE+sud/dOd+9s1/Ba+wRQsJrCb2bj+tz9\nkKQnimkHQLNUM9S3StK5ksaa2U5JX5B0rplNk+SSdkj6VAN7BNAAFcPv7gv7WXxHA3oZtLbfOCNZ\nv2LuD5vUycB95ScXJetjN6WvXz9666vJuj30iwH3dNTL89+TrP/H4huT9bcMeVNubdWBjuS2bQvS\nn08d+d8Xk/XBgG/4AUERfiAowg8ERfiBoAg/EBThB4Li0t1V2n5D/nDewwtzv90sSRo5pHW/2bjk\ng7emV/hguvxfB9uT9b/6yV/n1obtTm/7tx9enayPbcsfypOkbd35w3U3L7s0/djPP5SsHw848gNB\nEX4gKMIPBEX4gaAIPxAU4QeCIvxAUObuTdvZm22Mn22zm7a/In3jmQdzaycNTY83VzLtlqXJ+qsn\nHU7WR4z9v9za+6dsTW774dFdyfqM4emLUA+RJes9at7/r2OddXP+8/qOG3/WxE6aZ6Ov10u+P/2P\nkuHIDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBcT5/lS7YkD9m/OR7b6/rsUc925OsT/jSwzU/dnqU\nX7rmY5cl6w9+6ZZkvc3Sx48eL2+y6pl/8fPc2rrT/iS57dSPby66nZbDkR8IivADQRF+ICjCDwRF\n+IGgCD8QFOEHgqo4zm9mEyXdKalDkkta7u43m9kYSfdImiRph6T57v5C41ot19Sv5Z9T/662xclt\nt/5ZekbzL/7jbcn6Zy9ZkKzX47JTy5s+fMPBYcn6W4fkX6dAkv5oWHr68FvG51+D4Zq27uS2lb4f\ncTyo5sh/WNJV7n6apPdI+oyZnSbpWknr3X2qpPXZfQCDRMXwu/tud38ku31AvX8Ux0uaJ2llttpK\nSRc3qkkAxRvQe34zmyTpTEkbJXW4++6stEe9bwsADBJVh9/MRkq6V9IV7v5S35r3Xgiw34u1mdkS\nM+sys65u5c+dBqC5qgq/mbWrN/h3u/v3s8V7zWxcVh8naV9/27r7cnfvdPfOdrXuhJVANBXDb2Ym\n6Q5JW939q31KayUtym4vkrSm+PYANErFS3eb2SxJP5X0uKSj555ep973/f8i6SRJz6h3qG9/6rEG\n86W7U+zdZyTrv1qanor6sfd+I1kfbunty/RyT/qt3IwVV+fWpizbktzWTxqXrL9/1X8n63NG5j/+\nxz5/VXLbt3w7/ditaiCX7q44zu/uD0q5F2c//pIMBME3/ICgCD8QFOEHgiL8QFCEHwiK8ANBMUV3\nC9hzxcxk/cpP/2uy/pFRu5P1lBd6Dibrs+7OH6eXpI6N6cuOn7B644B7Qu2YohtARYQfCIrwA0ER\nfiAowg8ERfiBoAg/EBTj/MBxhHF+ABURfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjC\nDwRF+IGgCD8QFOEHgiL8QFAVw29mE83sP83sl2a2xcw+my2/3sx2mdmj2c+cxrcLoChDq1jnsKSr\n3P0RMxslabOZrctqy9z9K41rD0CjVAy/u++WtDu7fcDMtkoa3+jGADTWgN7zm9kkSWdKOjoH01Iz\ne8zMVpjZ6JxtlphZl5l1detQXc0CKE7V4TezkZLulXSFu78k6VZJUyRNU+8rg5v6287dl7t7p7t3\ntmt4AS0DKEJV4TezdvUG/253/74kuftedz/i7j2SbpM0vXFtAihaNZ/2m6Q7JG1196/2WT6uz2of\nkvRE8e0BaJRqPu0/R9JHJT1uZo9my66TtNDMpklySTskfaohHQJoiGo+7X9QUn/XAb+v+HYANAvf\n8AOCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRl7t68nZk9\nL+mZPovGSvpN0xoYmFbtrVX7kuitVkX2drK7v72aFZsa/jfs3KzL3TtLayChVXtr1b4keqtVWb3x\nsh8IivADQZUd/uUl7z+lVXtr1b4keqtVKb2V+p4fQHnKPvIDKEkp4TezC83sKTPbZmbXltFDHjPb\nYWaPZzMPd5Xcywoz22dmT/RZNsbM1pnZ09nvfqdJK6m3lpi5OTGzdKnPXavNeN30l/1m1ibpV5Le\nJ2mnpE2SFrr7L5vaSA4z2yGp091LHxM2sz+V9LKkO9399GzZjZL2u/sN2R/O0e7+uRbp7XpJL5c9\nc3M2ocy4vjNLS7pY0sdV4nOX6Gu+SnjeyjjyT5e0zd23u/trkr4raV4JfbQ8d98gaf8xi+dJWpnd\nXqne/zxNl9NbS3D33e7+SHb7gKSjM0uX+twl+ipFGeEfL+m5Pvd3qrWm/HZJD5jZZjNbUnYz/ejI\npk2XpD2SOspsph8VZ25upmNmlm6Z566WGa+Lxgd+bzTL3adJukjSZ7KXty3Je9+ztdJwTVUzNzdL\nPzNL/06Zz12tM14XrYzw75I0sc/9CdmyluDuu7Lf+yStVuvNPrz36CSp2e99JffzO600c3N/M0ur\nBZ67Vprxuozwb5I01cwmm9kwSQskrS2hjzcwsxOzD2JkZidKukCtN/vwWkmLstuLJK0psZfXaZWZ\nm/NmllbJz13LzXjt7k3/kTRHvZ/4/4+kz5fRQ05fUyT9IvvZUnZvklap92Vgt3o/G1ks6W2S1kt6\nWtIDksa0UG93SXpc0mPqDdq4knqbpd6X9I9JejT7mVP2c5foq5TnjW/4AUHxgR8QFOEHgiL8QFCE\nHwiK8ANBEX4gKMIPBEX4gaD+HxZynfp8HYP5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f2a8975208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApoAAAEYCAYAAAD8nFaxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f2a6eddf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def gen_image(arr):\n",
    "    two_d = (np.reshape(arr, (28, 28)) * 255).astype(np.uint8)\n",
    "    plt.imshow(two_d, interpolation='nearest')\n",
    "    return plt\n",
    "\n",
    "def plotNormalizedSpectrogram(normalizedSpecto, aDigImg):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    spectrogramData = normalizedSpecto\n",
    "    librosa.display.specshow(librosa.power_to_db(spectrogramData, ref=np.max), y_axis='mel', fmax=8000, x_axis='time')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def displaySample(predict, dataSet, wrongPred):\n",
    "    \n",
    "    n = wrongPred[0]\n",
    "    gn_predict = wrongPred[1]\n",
    "\n",
    "    AC_predict = np.argmax(predict[n][0])\n",
    "    IC_predict = np.argmax(predict[n][1])\n",
    "    \n",
    "    audio = np.reshape(dataSet[0][n], [128,44 ])\n",
    "    image = dataSet[1][n]\n",
    "    text = dataSet[2][n]\n",
    "    real_label = dataSet[4][n]\n",
    "\n",
    "    print(\"Showing sample number\",n)\n",
    "    print(\"Prediction - GN\",gn_predict,\"AC\",AC_predict, \"IC\",IC_predict)\n",
    "    \n",
    "    print(\"Real label\",real_label)\n",
    "    digImg = gen_image(image)\n",
    "    plotNormalizedSpectrogram(audio, digImg)\n",
    "\n",
    "_, validationSet = loadData_TwoModal(\"0.9\",\"0.9\")\n",
    "    \n",
    "# GN Right - AC/IC wrong\n",
    "#1262 GN 7 AC 0 IC 1\n",
    "#1413 GN 7 AC 8 IC 3\n",
    "#2241\n",
    "#3008\n",
    "#3012\n",
    "#3087\n",
    "#3457\n",
    "\n",
    "\n",
    "correct_index = correct_samples[1413] \n",
    "\n",
    "# 1, 14, 17 where both AC/IC were incorrect\n",
    "incorrect_index = incorrect_samples[0] # 0, 69 where AC and IC were correct while GN fucked up\n",
    "\n",
    "\n",
    "displaySample(validationSet,Display_Validation_Data,incorrect_index)\n",
    "\n",
    "# GN Wrong - AC/IC Correct\n",
    "#displaySample(validationSet,Display_Validation_Data,incorrect_samples[0] )\n",
    "#displaySample(validationSet,Display_Validation_Data,incorrect_samples[69] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No one correct 26 ( 29.545455 of all incorrect samples)\n",
      "GN had 7 when both AC/IC were incorrect but 0 wrong when AC/IC were correct\n",
      "AC had 53 wrong while IC had 9 wrong\n"
     ]
    }
   ],
   "source": [
    "AC_wrong, IC_wrong, GN_wrong, GN_right = 0,0,0,0\n",
    "c = 0\n",
    "for i in range(len(incorrect_samples)):\n",
    "    nsample = incorrect_samples[i][0] # index, 1 is gn prediction\n",
    "    gn_predict = incorrect_samples[i][1] \n",
    "    \n",
    "    correct_label = np.argmax(validationSet[nsample][2])\n",
    "    AC_predict = np.argmax(validationSet[nsample][0])\n",
    "    IC_predict = np.argmax(validationSet[nsample][1])\n",
    "    if(AC_predict != correct_label and IC_predict != correct_label):\n",
    "        c += 1 #print(nsample)\n",
    "    else:\n",
    "        if (AC_predict != correct_label):\n",
    "            AC_wrong += 1\n",
    "        if (IC_predict != correct_label):\n",
    "            IC_wrong += 1\n",
    "    \n",
    "    if(AC_predict == correct_label and IC_predict == correct_label):\n",
    "        GN_wrong += 1\n",
    "        \n",
    "for i in range(len(correct_samples)):\n",
    "    nsample = correct_samples[i][0] # index, 1 is gn prediction\n",
    "    gn_predict = correct_samples[i][1] \n",
    "    \n",
    "    correct_label = np.argmax(validationSet[nsample][2])\n",
    "    AC_predict = np.argmax(validationSet[nsample][0])\n",
    "    IC_predict = np.argmax(validationSet[nsample][1])\n",
    "    \n",
    "    if(AC_predict != correct_label and IC_predict != correct_label):\n",
    "        if(gn_predict == correct_label):\n",
    "            GN_right += 1\n",
    "        \n",
    "\n",
    "print(\"No one correct\",c, \"(\",\"{:2f}\".format((c/len(incorrect_samples))*100),\"of all incorrect samples)\") \n",
    "print(\"GN had\",GN_right,\"when both AC/IC were incorrect but\",GN_wrong,\"wrong when AC/IC were correct\")\n",
    "print(\"AC had\",AC_wrong, \"wrong while IC had\",IC_wrong,\"wrong\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
