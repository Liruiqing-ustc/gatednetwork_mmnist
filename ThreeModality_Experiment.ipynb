{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.patches as mpatches\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from random import randint\n",
    "from random import shuffle\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pickle\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "reset_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ac_sets = [\"0.7\", \"0.8\", \"0.9\"]\n",
    "ic_sets = [\"0.7\", \"0.8\", \"0.9\"]\n",
    "tc_sets = [\"0.7\", \"0.8\", \"0.9\"]\n",
    "\n",
    "\n",
    "def loadData_ThreeModal(ac_per, ic_per, tc_per,printSize=False):\n",
    "    train_AC = pickle.load(open('data/AC_Training_'+ac_per+'.p', mode='rb'))\n",
    "    valid_AC = pickle.load(open('data/AC_Validation_'+ac_per+'.p', mode='rb'))\n",
    "\n",
    "    train_IC = pickle.load(open('data/IC_Training_'+ic_per+'.p', mode='rb'))\n",
    "    valid_IC = pickle.load(open('data/IC_Validation_'+ic_per+'.p', mode='rb'))\n",
    "    \n",
    "    train_TC = pickle.load(open('data/TC_Training_'+tc_per+'.p', mode='rb'))\n",
    "    valid_TC = pickle.load(open('data/TC_Validation_'+tc_per+'.p', mode='rb'))\n",
    "    \n",
    "    if(printSize):\n",
    "        print(\"Validation samples\",len(valid_AC[0]))\n",
    "        print(\"Training samples\",len(train_AC[0]))\n",
    "\n",
    "    \n",
    "    #Training Set\n",
    "    trainHolder = []\n",
    "    for i in range(len(train_AC[0])):\n",
    "        trainHolder.append([train_AC[0][i],train_IC[0][i],train_TC[0][i],train_AC[1][i]])\n",
    "    #Validation set\n",
    "    validHolder = []    \n",
    "    for i in range(len(valid_AC[0])):\n",
    "        validHolder.append([valid_AC[0][i],valid_IC[0][i],valid_TC[0][i],valid_AC[1][i]])\n",
    "    \n",
    "    return trainHolder, validHolder\n",
    "        \n",
    "trainingSet, validationSet = loadData_ThreeModal(\"0.9\",\"0.9\",\"0.9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training set: 20116\n",
      "Number of samples in validation set: 3549\n",
      "Level of accuracy: 0.7\n",
      "Training accuracy for\n",
      "AC is 73.17%\n",
      "IC is 70.83%\n",
      "TC is 70.10%\n",
      "Validation accuracy for\n",
      "AC is 70.95%\n",
      "IC is 71.46%\n",
      "TC is 70.84%\n",
      "\n",
      "Level of accuracy: 0.8\n",
      "Training accuracy for\n",
      "AC is 83.68%\n",
      "IC is 79.66%\n",
      "TC is 81.14%\n",
      "Validation accuracy for\n",
      "AC is 81.40%\n",
      "IC is 80.16%\n",
      "TC is 81.35%\n",
      "\n",
      "Level of accuracy: 0.9\n",
      "Training accuracy for\n",
      "AC is 94.58%\n",
      "IC is 93.11%\n",
      "TC is 88.29%\n",
      "Validation accuracy for\n",
      "AC is 89.41%\n",
      "IC is 91.21%\n",
      "TC is 88.87%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the accuracy of all models\n",
    "print(\"Number of samples in training set:\",len(trainingSet))\n",
    "print(\"Number of samples in validation set:\",len(validationSet))\n",
    "for acc_level in ac_sets:\n",
    "    trainingSet, validationSet = loadData_ThreeModal(acc_level,acc_level,acc_level)\n",
    "    print(\"Level of accuracy:\",acc_level)\n",
    "    t_ac = 0\n",
    "    t_ic = 0\n",
    "    t_tc = 0\n",
    "\n",
    "    for i in range(len(trainingSet)):\n",
    "        if(np.argmax(trainingSet[i][0]) == np.argmax(trainingSet[i][3])):\n",
    "            t_ac += 1\n",
    "        if(np.argmax(trainingSet[i][1]) == np.argmax(trainingSet[i][3])):\n",
    "            t_ic += 1\n",
    "        if(np.argmax(trainingSet[i][2]) == np.argmax(trainingSet[i][3])):\n",
    "            t_tc += 1\n",
    "\n",
    "    print(\"Training accuracy for\")\n",
    "    print(\"AC is {:.2f}%\".format (t_ac/len(trainingSet)*100))       \n",
    "    print(\"IC is {:.2f}%\".format (t_ic/len(trainingSet)*100))      \n",
    "    print(\"TC is {:.2f}%\".format (t_tc/len(trainingSet)*100))\n",
    "\n",
    "    v_ac = 0\n",
    "    v_ic = 0\n",
    "    v_tc = 0\n",
    "\n",
    "    for i in range(len(validationSet)):\n",
    "        if(np.argmax(validationSet[i][0]) == np.argmax(validationSet[i][3])):\n",
    "            v_ac += 1\n",
    "        if(np.argmax(validationSet[i][1]) == np.argmax(validationSet[i][3])):\n",
    "            v_ic += 1\n",
    "        if(np.argmax(validationSet[i][2]) == np.argmax(validationSet[i][3])):\n",
    "            v_tc += 1\n",
    "    \n",
    "\n",
    "    print(\"Validation accuracy for\")\n",
    "    print(\"AC is {:.2f}%\".format (v_ac/len(validationSet)*100))\n",
    "    print(\"IC is {:.2f}%\".format (v_ic/len(validationSet)*100))  \n",
    "    print(\"TC is {:.2f}%\".format (v_tc/len(validationSet)*100)) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AC/IC/TC at 0.7 / 0.7 / 0.7 is 98.39%\n",
      "Validation AC/IC/TC at 0.7 / 0.7 / 0.8 is 98.96%\n",
      "Validation AC/IC/TC at 0.7 / 0.7 / 0.9 is 99.41%\n",
      "Validation AC/IC/TC at 0.7 / 0.8 / 0.7 is 98.68%\n",
      "Validation AC/IC/TC at 0.7 / 0.8 / 0.8 is 99.24%\n",
      "Validation AC/IC/TC at 0.7 / 0.8 / 0.9 is 99.66%\n",
      "Validation AC/IC/TC at 0.7 / 0.9 / 0.7 is 99.41%\n",
      "Validation AC/IC/TC at 0.7 / 0.9 / 0.8 is 99.61%\n",
      "Validation AC/IC/TC at 0.7 / 0.9 / 0.9 is 99.77%\n",
      "Validation AC/IC/TC at 0.8 / 0.7 / 0.7 is 99.21%\n",
      "Validation AC/IC/TC at 0.8 / 0.7 / 0.8 is 99.44%\n",
      "Validation AC/IC/TC at 0.8 / 0.7 / 0.9 is 99.75%\n",
      "Validation AC/IC/TC at 0.8 / 0.8 / 0.7 is 99.24%\n",
      "Validation AC/IC/TC at 0.8 / 0.8 / 0.8 is 99.49%\n",
      "Validation AC/IC/TC at 0.8 / 0.8 / 0.9 is 99.83%\n",
      "Validation AC/IC/TC at 0.8 / 0.9 / 0.7 is 99.72%\n",
      "Validation AC/IC/TC at 0.8 / 0.9 / 0.8 is 99.72%\n",
      "Validation AC/IC/TC at 0.8 / 0.9 / 0.9 is 99.92%\n",
      "Validation AC/IC/TC at 0.9 / 0.7 / 0.7 is 99.49%\n",
      "Validation AC/IC/TC at 0.9 / 0.7 / 0.8 is 99.69%\n",
      "Validation AC/IC/TC at 0.9 / 0.7 / 0.9 is 99.80%\n",
      "Validation AC/IC/TC at 0.9 / 0.8 / 0.7 is 99.61%\n",
      "Validation AC/IC/TC at 0.9 / 0.8 / 0.8 is 99.86%\n",
      "Validation AC/IC/TC at 0.9 / 0.8 / 0.9 is 99.94%\n",
      "Validation AC/IC/TC at 0.9 / 0.9 / 0.7 is 99.86%\n",
      "Validation AC/IC/TC at 0.9 / 0.9 / 0.8 is 99.92%\n",
      "Validation AC/IC/TC at 0.9 / 0.9 / 0.9 is 99.94%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for acc_level_a in ac_sets:\n",
    "    for acc_level_b in ic_sets:\n",
    "        for acc_level_c in tc_sets:\n",
    "\n",
    "\n",
    "            # Set to false to print out in table for excel format\n",
    "            displayNotebook = True\n",
    "\n",
    "            # AC / IC AND AC/TC\n",
    "            trainingSet, validationSet = loadData_ThreeModal(acc_level_a,acc_level_b,acc_level_c)\n",
    "\n",
    "            trainKnowledge = 0\n",
    "            validKnowledge = 0\n",
    "\n",
    "            for i in range(len(trainingSet)):\n",
    "                if(np.argmax(trainingSet[i][0]) == np.argmax(trainingSet[i][3])\n",
    "                  or\n",
    "                  np.argmax(trainingSet[i][1]) == np.argmax(trainingSet[i][3])\n",
    "                  or\n",
    "                  np.argmax(trainingSet[i][2]) == np.argmax(trainingSet[i][3])\n",
    "                  ):\n",
    "                    trainKnowledge += 1\n",
    "\n",
    "\n",
    "            for i in range(len(validationSet)):\n",
    "                if(np.argmax(validationSet[i][0]) == np.argmax(validationSet[i][3])\n",
    "                   or\n",
    "                   np.argmax(validationSet[i][1]) == np.argmax(validationSet[i][3])\n",
    "                   or\n",
    "                   np.argmax(validationSet[i][2]) == np.argmax(validationSet[i][3])\n",
    "                  ):\n",
    "                        validKnowledge += 1\n",
    "\n",
    "            if(displayNotebook):\n",
    "                #print(\"Training AC/IC/TC at\",acc_level_a,\"/\",acc_level_b,\"/\",acc_level_c,\"is {:.2f}%\".format (trainKnowledge/len(trainingSet)*100)) \n",
    "                #print(\"Validation AC/IC/TC at\",acc_level_a,\"/\",acc_level_b,\"/\",acc_level_c,\"is {:.2f}%\".format (validKnowledge/len(validationSet)*100)) \n",
    "                print(\"Validation AC/IC/TC at\",acc_level_a,\"/\",acc_level_b,\"/\",acc_level_c,\"is {:.2f}%\".format (validKnowledge/len(validationSet)*100)) \n",
    "                #print()\n",
    "            else:\n",
    "                a=(\"{:.2f}\".format (train_agreement_ac_ic/len(trainingSet)*100)) \n",
    "                b=(\" {:.2f}\".format (valid_agreement_ic_tc/len(validationSet)*100)) \n",
    "                print(a+b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50.52 52.16 47.31\n",
      " 56.80 59.09 55.96\n",
      " 65.00 63.71 62.38\n",
      " 59.40 58.07 54.66\n",
      " 66.24 66.38 63.51\n",
      " 74.47 72.27 70.13\n",
      " 64.75 63.76 63.99\n",
      " 72.02 73.01 73.71\n",
      " 81.66 79.74 80.73\n"
     ]
    }
   ],
   "source": [
    "# Check the agreement factor between components\n",
    "for acc_level_a in ac_sets:\n",
    "    for acc_level_b in ic_sets:\n",
    "        \n",
    "        # Set to false to print out in table for excel format\n",
    "        displayNotebook = False\n",
    "        # AC / IC AND AC/TC\n",
    "        trainingSet, validationSet = loadData_ThreeModal(acc_level_a,acc_level_b,acc_level_b)\n",
    "        trainingSet_ICTC, validationSet_ICTC = loadData_ThreeModal(acc_level_a,acc_level_a,acc_level_b)\n",
    "\n",
    "        train_agreement_ac_ic = 0\n",
    "        train_agreement_ac_tc = 0\n",
    "        train_agreement_ic_tc = 0\n",
    "\n",
    "        for i in range(len(trainingSet)):\n",
    "            if(np.argmax(trainingSet[i][0]) == np.argmax(trainingSet[i][1])):\n",
    "                train_agreement_ac_ic += 1\n",
    "            if(np.argmax(trainingSet[i][0]) == np.argmax(trainingSet[i][2])):\n",
    "                train_agreement_ac_tc += 1\n",
    "            if(np.argmax(trainingSet_ICTC[i][1]) == np.argmax(trainingSet_ICTC[i][2])):\n",
    "                train_agreement_ic_tc += 1\n",
    "\n",
    "        valid_agreement_ac_ic = 0\n",
    "        valid_agreement_ac_tc = 0\n",
    "        valid_agreement_ic_tc = 0\n",
    "\n",
    "        for i in range(len(validationSet)):\n",
    "            if(np.argmax(validationSet[i][0]) == np.argmax(validationSet[i][1])):\n",
    "                valid_agreement_ac_ic += 1\n",
    "            if(np.argmax(validationSet[i][0]) == np.argmax(validationSet[i][2])):\n",
    "                valid_agreement_ac_tc += 1\n",
    "            if(np.argmax(validationSet_ICTC[i][1]) == np.argmax(validationSet_ICTC[i][2])):\n",
    "                valid_agreement_ic_tc += 1\n",
    "        if(displayNotebook):\n",
    "            print(\"Training AC/IC at\",acc_level_a,\"/\",acc_level_b,\"is {:.2f}%\".format (train_agreement_ac_ic/len(trainingSet)*100)) \n",
    "            print(\"Training AC/TC at\",acc_level_a,\"/\",acc_level_b,\"is {:.2f}%\".format (train_agreement_ac_tc/len(trainingSet)*100)) \n",
    "            print(\"Training IC/TC at\",acc_level_a,\"/\",acc_level_b,\"is {:.2f}%\".format (train_agreement_ic_tc/len(trainingSet)*100)) \n",
    "            print(\"Validation AC/IC at\",acc_level_a,\"/\",acc_level_b,\"is {:.2f}%\".format (valid_agreement_ac_ic/len(validationSet)*100)) \n",
    "            print(\"Validation AC/TC at\",acc_level_a,\"/\",acc_level_b,\"is {:.2f}%\".format (valid_agreement_ac_tc/len(validationSet)*100)) \n",
    "            print(\"Validation IC/TC at\",acc_level_a,\"/\",acc_level_b,\"is {:.2f}%\".format (valid_agreement_ic_tc/len(validationSet)*100)) \n",
    "            print()\n",
    "        else:\n",
    "            a=(\"{:.2f}\".format (train_agreement_ac_ic/len(trainingSet)*100)) \n",
    "            b=(\" {:.2f}\".format (train_agreement_ac_tc/len(trainingSet)*100)) \n",
    "            c=(\" {:.2f}\".format (train_agreement_ic_tc/len(trainingSet)*100)) \n",
    "            e=(\" {:.2f}\".format (valid_agreement_ac_ic/len(validationSet)*100)) \n",
    "            f=(\" {:.2f}\".format (valid_agreement_ac_tc/len(validationSet)*100)) \n",
    "            g=(\" {:.2f}\".format (valid_agreement_ic_tc/len(validationSet)*100)) \n",
    "            # Print only validation\n",
    "            print(e+f+g)\n",
    "\n",
    "\n",
    "\n",
    "### TODO: Check this, something wrong here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AC/IC/TC at 0.7 / 0.7 / 0.7 is 33.81%\n",
      "Validation AC/IC/TC at 0.7 / 0.7 / 0.7 is 33.08%\n",
      "\n",
      "Training AC/IC/TC at 0.7 / 0.7 / 0.8 is 40.03%\n",
      "Validation AC/IC/TC at 0.7 / 0.7 / 0.8 is 39.31%\n",
      "\n",
      "Training AC/IC/TC at 0.7 / 0.7 / 0.9 is 44.50%\n",
      "Validation AC/IC/TC at 0.7 / 0.7 / 0.9 is 43.79%\n",
      "\n",
      "Training AC/IC/TC at 0.7 / 0.8 / 0.7 is 39.50%\n",
      "Validation AC/IC/TC at 0.7 / 0.8 / 0.7 is 38.74%\n",
      "\n",
      "Training AC/IC/TC at 0.7 / 0.8 / 0.8 is 45.78%\n",
      "Validation AC/IC/TC at 0.7 / 0.8 / 0.8 is 45.08%\n",
      "\n",
      "Training AC/IC/TC at 0.7 / 0.8 / 0.9 is 50.37%\n",
      "Validation AC/IC/TC at 0.7 / 0.8 / 0.9 is 49.73%\n",
      "\n",
      "Training AC/IC/TC at 0.7 / 0.9 / 0.7 is 48.17%\n",
      "Validation AC/IC/TC at 0.7 / 0.9 / 0.7 is 46.18%\n",
      "\n",
      "Training AC/IC/TC at 0.7 / 0.9 / 0.8 is 55.19%\n",
      "Validation AC/IC/TC at 0.7 / 0.9 / 0.8 is 53.06%\n",
      "\n",
      "Training AC/IC/TC at 0.7 / 0.9 / 0.9 is 60.10%\n",
      "Validation AC/IC/TC at 0.7 / 0.9 / 0.9 is 57.71%\n",
      "\n",
      "Training AC/IC/TC at 0.8 / 0.7 / 0.7 is 39.55%\n",
      "Validation AC/IC/TC at 0.8 / 0.7 / 0.7 is 38.38%\n",
      "\n",
      "Training AC/IC/TC at 0.8 / 0.7 / 0.8 is 47.04%\n",
      "Validation AC/IC/TC at 0.8 / 0.7 / 0.8 is 45.65%\n",
      "\n",
      "Training AC/IC/TC at 0.8 / 0.7 / 0.9 is 52.21%\n",
      "Validation AC/IC/TC at 0.8 / 0.7 / 0.9 is 51.00%\n",
      "\n",
      "Training AC/IC/TC at 0.8 / 0.8 / 0.7 is 45.77%\n",
      "Validation AC/IC/TC at 0.8 / 0.8 / 0.7 is 44.66%\n",
      "\n",
      "Training AC/IC/TC at 0.8 / 0.8 / 0.8 is 53.37%\n",
      "Validation AC/IC/TC at 0.8 / 0.8 / 0.8 is 52.04%\n",
      "\n",
      "Training AC/IC/TC at 0.8 / 0.8 / 0.9 is 58.65%\n",
      "Validation AC/IC/TC at 0.8 / 0.8 / 0.9 is 57.62%\n",
      "\n",
      "Training AC/IC/TC at 0.8 / 0.9 / 0.7 is 54.39%\n",
      "Validation AC/IC/TC at 0.8 / 0.9 / 0.7 is 51.82%\n",
      "\n",
      "Training AC/IC/TC at 0.8 / 0.9 / 0.8 is 62.92%\n",
      "Validation AC/IC/TC at 0.8 / 0.9 / 0.8 is 59.85%\n",
      "\n",
      "Training AC/IC/TC at 0.8 / 0.9 / 0.9 is 68.63%\n",
      "Validation AC/IC/TC at 0.8 / 0.9 / 0.9 is 65.54%\n",
      "\n",
      "Training AC/IC/TC at 0.9 / 0.7 / 0.7 is 44.19%\n",
      "Validation AC/IC/TC at 0.9 / 0.7 / 0.7 is 42.46%\n",
      "\n",
      "Training AC/IC/TC at 0.9 / 0.7 / 0.8 is 52.67%\n",
      "Validation AC/IC/TC at 0.9 / 0.7 / 0.8 is 50.27%\n",
      "\n",
      "Training AC/IC/TC at 0.9 / 0.7 / 0.9 is 58.60%\n",
      "Validation AC/IC/TC at 0.9 / 0.7 / 0.9 is 56.27%\n",
      "\n",
      "Training AC/IC/TC at 0.9 / 0.8 / 0.7 is 51.14%\n",
      "Validation AC/IC/TC at 0.9 / 0.8 / 0.7 is 49.11%\n",
      "\n",
      "Training AC/IC/TC at 0.9 / 0.8 / 0.8 is 59.72%\n",
      "Validation AC/IC/TC at 0.9 / 0.8 / 0.8 is 57.06%\n",
      "\n",
      "Training AC/IC/TC at 0.9 / 0.8 / 0.9 is 65.75%\n",
      "Validation AC/IC/TC at 0.9 / 0.8 / 0.9 is 63.26%\n",
      "\n",
      "Training AC/IC/TC at 0.9 / 0.9 / 0.7 is 61.33%\n",
      "Validation AC/IC/TC at 0.9 / 0.9 / 0.7 is 57.37%\n",
      "\n",
      "Training AC/IC/TC at 0.9 / 0.9 / 0.8 is 71.01%\n",
      "Validation AC/IC/TC at 0.9 / 0.9 / 0.8 is 66.02%\n",
      "\n",
      "Training AC/IC/TC at 0.9 / 0.9 / 0.9 is 77.57%\n",
      "Validation AC/IC/TC at 0.9 / 0.9 / 0.9 is 72.41%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the agreement factor between all components at the same time\n",
    "for acc_level_a in ac_sets:\n",
    "    for acc_level_b in ic_sets:\n",
    "        for acc_level_c in tc_sets:\n",
    "\n",
    "            # AC / IC AND AC/TC\n",
    "            trainingSet, validationSet = loadData_ThreeModal(acc_level_a,acc_level_b,acc_level_c)\n",
    "\n",
    "            train_agreement_ac_ic_tc = 0\n",
    "\n",
    "            for i in range(len(trainingSet)):\n",
    "                if(np.argmax(trainingSet[i][0]) == np.argmax(trainingSet[i][1])):\n",
    "                    if(np.argmax(trainingSet[i][0]) == np.argmax(trainingSet[i][2])):\n",
    "                        train_agreement_ac_ic_tc += 1\n",
    "\n",
    "            valid_agreement_ac_ic_tc = 0\n",
    "\n",
    "            for i in range(len(validationSet)):\n",
    "                if(np.argmax(validationSet[i][0]) == np.argmax(validationSet[i][1])):\n",
    "                    if(np.argmax(validationSet[i][0]) == np.argmax(validationSet[i][2])):\n",
    "                        valid_agreement_ac_ic_tc += 1\n",
    "\n",
    "            if(displayNotebook):\n",
    "                print(\"Training AC/IC/TC at\",acc_level_a,\"/\",acc_level_b,\"/\",acc_level_c,\"is {:.2f}%\".format (train_agreement_ac_ic_tc/len(trainingSet)*100)) \n",
    "                print(\"Validation AC/IC/TC at\",acc_level_a,\"/\",acc_level_b,\"/\",acc_level_c,\"is {:.2f}%\".format (valid_agreement_ac_ic_tc/len(validationSet)*100)) \n",
    "                print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running GN2_10, GN2_50, GN3_10, GN3_50\n",
      "Running GN2_10 Start Training of AC,IC,TC 0.9 0.9 0.9\n",
      "Max accuracy at epoch 989  was: 0.962243\n",
      "Recall score:  ['97.89%', '95.91%', '97.97%', '95.66%', '96.64%', '94.93%', '97.19%', '95.95%', '95.45%', '94.92%']\n",
      "Running GN2_50 Start Training of AC,IC,TC 0.9 0.9 0.9\n",
      "Max accuracy at epoch 726  was: 0.992392\n",
      "Recall score:  ['99.40%', '99.37%', '99.42%', '99.46%', '98.88%', '99.20%', '99.44%', '99.73%', '98.13%', '98.59%']\n",
      "Running GN3_10 Start Training of AC,IC,TC 0.9 0.9 0.9\n",
      "Max accuracy at epoch 974  was: 0.963934\n",
      "Recall score:  ['97.58%', '96.86%', '97.68%', '95.66%', '97.48%', '91.20%', '98.03%', '96.76%', '97.06%', '96.05%']\n",
      "Running GN3_50 Start Training of AC,IC,TC 0.9 0.9 0.9\n",
      "Max accuracy at epoch 983  was: 0.993238\n",
      "Recall score:  ['99.09%', '99.37%', '99.42%', '99.73%', '98.04%', '98.93%', '100.00%', '99.73%', '98.66%', '98.59%']\n"
     ]
    }
   ],
   "source": [
    "### Testing the recall score for all models\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "testNetworks_f = [2,3]\n",
    "testNetworks_w = [10,50]\n",
    "print(\"Start running GN2_10, GN2_50, GN3_10, GN3_50\")\n",
    "for fuse in testNetworks_f:\n",
    "    for weight in testNetworks_w:\n",
    "        \n",
    "        FUSION = fuse\n",
    "        WEIGHT_SIZE = weight\n",
    "\n",
    "        ac = \"0.9\"\n",
    "        ic = \"0.9\"\n",
    "        tc = \"0.9\"\n",
    "        \n",
    "        trainingSet, validationSet = loadData_ThreeModal(ac,ic,tc)\n",
    "        reset_graph()\n",
    "        print(\"Running GN\"+str(FUSION)+\"_\"+str(WEIGHT_SIZE),\"Start Training of AC,IC,TC\",ac,ic,tc)\n",
    "\n",
    "        pkeep = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "        # 10 features\n",
    "        x1 = [row[0] for row in trainingSet] \n",
    "        x2 = [row[1] for row in trainingSet] \n",
    "        x3 = [row[2] for row in trainingSet] \n",
    "        y =  [row[3] for row in trainingSet] \n",
    "\n",
    "        x1_test = [row[0] for row in validationSet] \n",
    "        x2_test = [row[1] for row in validationSet] \n",
    "        x3_test = [row[2] for row in validationSet] \n",
    "        y_test =  [row[3] for row in validationSet] \n",
    "\n",
    "        x1_input = tf.placeholder(tf.float32, [None, 10])\n",
    "        x2_input = tf.placeholder(tf.float32, [None, 10])\n",
    "        x3_input = tf.placeholder(tf.float32, [None, 10])\n",
    "        y_label = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "        # Other method according to paper\n",
    "        o_Wv = tf.Variable(tf.random_uniform([ 10, WEIGHT_SIZE],  minval=-0.2,maxval=0.2))\n",
    "        o_Wt = tf.Variable(tf.random_uniform([ 10, WEIGHT_SIZE],  minval=-0.2,maxval=0.2))\n",
    "        o_Wd = tf.Variable(tf.random_uniform([ 10, WEIGHT_SIZE],  minval=-0.2,maxval=0.2))\n",
    "\n",
    "        o_Wvt = tf.Variable(tf.random_uniform([ 20, WEIGHT_SIZE],  minval=-0.2,maxval=0.2))\n",
    "        o_Wvd = tf.Variable(tf.random_uniform([ 20, WEIGHT_SIZE],  minval=-0.2,maxval=0.2))\n",
    "        o_Wtd = tf.Variable(tf.random_uniform([ 20, WEIGHT_SIZE],  minval=-0.2,maxval=0.2))\n",
    "\n",
    "        o_hv = tf.nn.tanh(tf.matmul(x1_input, o_Wv))\n",
    "        o_ht = tf.nn.tanh(tf.matmul(x2_input, o_Wt))\n",
    "        o_hd = tf.nn.tanh(tf.matmul(x3_input, o_Wd))\n",
    "\n",
    "        o_vt = tf.nn.relu(tf.matmul(tf.concat((x1_input,x2_input), axis=1), o_Wvt))\n",
    "        o_vd = tf.nn.relu(tf.matmul(tf.concat((x1_input,x3_input), axis=1), o_Wvd)) \n",
    "        o_td = tf.nn.relu(tf.matmul(tf.concat((x2_input,x3_input), axis=1), o_Wtd))\n",
    "\n",
    "        o_Hvt = tf.multiply(o_vt, o_hv) + tf.multiply((1-o_vt), o_ht)\n",
    "        o_Hvd = tf.multiply(o_vd, o_hv) + tf.multiply((1-o_vd), o_hd)\n",
    "        o_Htd = tf.multiply(o_td, o_ht) + tf.multiply((1-o_td), o_hd)\n",
    "\n",
    "\n",
    "        if(WEIGHT_SIZE == 10):\n",
    "            # GN2_10\n",
    "            if(FUSION == 2):\n",
    "                o_h = tf.nn.softmax(o_Hvt + o_Htd) \n",
    "            # GN3_10\n",
    "            else:\n",
    "                o_h = tf.nn.softmax(o_Hvt + o_Htd + o_Hvd)  \n",
    "        else:\n",
    "            concatSize = 0\n",
    "            if(FUSION == 2):\n",
    "                # 2 fuse 50\n",
    "                concatSize = 100\n",
    "                o_h_temp = tf.concat([o_Hvt,o_Htd],axis=1)\n",
    "            else:\n",
    "                # 3 fuse 50\n",
    "                concatSize = 150\n",
    "                o_h_temp = tf.concat([o_Hvt,o_Htd, o_Hvd],axis=1)\n",
    "\n",
    "            W13  = tf.Variable(tf.random_uniform([concatSize, 256],  minval=-0.2,maxval=0.2))\n",
    "            B13 =  tf.Variable(tf.random_normal([256], mean=0.1,stddev=.1))\n",
    "            W23  = tf.Variable(tf.random_uniform([256, 64],  minval=-0.2,maxval=0.2))\n",
    "            B23 =  tf.Variable(tf.random_normal([64], mean=0.1,stddev=.1))\n",
    "            W33  = tf.Variable(tf.random_uniform([64, 10],  minval=-0.2,maxval=0.2))\n",
    "            B33 =  tf.Variable(tf.random_normal([10], mean=0.1,stddev=.1))\n",
    "\n",
    "            L13 =  tf.nn.relu(tf.add(tf.matmul(o_h_temp, W13), B13))\n",
    "            L13_dropout = tf.nn.dropout(L13,pkeep)\n",
    "\n",
    "            L23 =  tf.nn.relu(tf.add(tf.matmul(L13_dropout, W23), B23))\n",
    "            L23_dropout = tf.nn.dropout(L23,pkeep)\n",
    "\n",
    "            o_h3 =  tf.add(tf.matmul(L23_dropout, W33), B33)\n",
    "            o_h = tf.nn.softmax(o_h3)  \n",
    "\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=o_h, labels=y_label)\n",
    "        cross_entropy = tf.reduce_mean(cross_entropy) * 100\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "        correct_pred = tf.equal(tf.argmax(o_h, 1), tf.argmax(y_label, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        epochs = 1000\n",
    "\n",
    "        t_acc = []\n",
    "        v_acc = []\n",
    "\n",
    "        gn_t_pred = []\n",
    "        gn_v_pred = []\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "\n",
    "            maxEpoch, maxValid = 0,0\n",
    "            for epoch in range(epochs):\n",
    "\n",
    "                dropout = 0.5\n",
    "                _, tacc = sess.run([train_step, accuracy], feed_dict={x1_input: x1, x2_input: x2, x3_input: x3,\n",
    "                                                                      y_label: y,  pkeep: dropout})\n",
    "\n",
    "                vacc = sess.run(accuracy, feed_dict={x1_input: x1_test, x2_input: x2_test, x3_input: x3_test, \n",
    "                                                     y_label: y_test, pkeep: dropout})\n",
    "                v_acc.append(vacc)\n",
    "                #print(\"valid acc\", vacc)\n",
    "                if(vacc >maxValid):\n",
    "                    maxEpoch = epoch\n",
    "                    maxValid = vacc\n",
    "                    gn_v_pred = sess.run(o_h, feed_dict={x1_input: x1_test, x2_input: x2_test,  x3_input: x3_test, y_label: y_test,pkeep:1})\n",
    "\n",
    "            print(\"Max accuracy at epoch\",maxEpoch,\" was:\",maxValid)\n",
    "            #tt = sess.run(o_h, feed_dict={x1_input: x1, x2_input: x2, x3_input: x3, y_label: y, pkeep:1})\n",
    "            #vv = sess.run(o_h, feed_dict={x1_input: x1_test, x2_input: x2_test,  x3_input: x3_test, y_label: y_test,pkeep:1})\n",
    "            placehold = [0] * len(validationSet)\n",
    "            yyy = [np.argmax(row[3]) for row in validationSet]\n",
    "            for i in range(len(validationSet)):\n",
    "                arr = np.argmax(gn_v_pred[i])\n",
    "                placehold[i] = arr\n",
    "\n",
    "            precision, recall, fscore, support = score(yyy, placehold)\n",
    "            arr_recall = ['{:.2f}%'.format(i*100) for i in recall]\n",
    "\n",
    "            print('Recall score: ',arr_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GN3_50 for 0.9 0.9 0.9 got max accuracy at epoch 931  was: 99.2392241955\n",
      "Training done - took 762.140716791153 seconds\n"
     ]
    }
   ],
   "source": [
    "# Training time for GN\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "### GATING NETWORK\n",
    "\n",
    "FUSION = 3\n",
    "WEIGHT_SIZE = 50\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "trainingSet, validationSet = loadData_ThreeModal(\"0.9\",\"0.9\",\"0.9\")\n",
    "\n",
    "pkeep = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "# 10 features\n",
    "x1 = [row[0] for row in trainingSet] \n",
    "x2 = [row[1] for row in trainingSet] \n",
    "x3 = [row[2] for row in trainingSet] \n",
    "y =  [row[3] for row in trainingSet] \n",
    "\n",
    "x1_test = [row[0] for row in validationSet] \n",
    "x2_test = [row[1] for row in validationSet] \n",
    "x3_test = [row[2] for row in validationSet] \n",
    "y_test =  [row[3] for row in validationSet] \n",
    "\n",
    "x1_input = tf.placeholder(tf.float32, [None, 10])\n",
    "x2_input = tf.placeholder(tf.float32, [None, 10])\n",
    "x3_input = tf.placeholder(tf.float32, [None, 10])\n",
    "y_label = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# Other method according to paper\n",
    "o_Wv = tf.Variable(tf.random_uniform([ 10, WEIGHT_SIZE],  minval=-0.2,maxval=0.2))\n",
    "o_Wt = tf.Variable(tf.random_uniform([ 10, WEIGHT_SIZE],  minval=-0.2,maxval=0.2))\n",
    "o_Wd = tf.Variable(tf.random_uniform([ 10, WEIGHT_SIZE],  minval=-0.2,maxval=0.2))\n",
    "\n",
    "o_Wvt = tf.Variable(tf.random_uniform([ 20, WEIGHT_SIZE],  minval=-0.2,maxval=0.2))\n",
    "o_Wvd = tf.Variable(tf.random_uniform([ 20, WEIGHT_SIZE],  minval=-0.2,maxval=0.2))\n",
    "o_Wtd = tf.Variable(tf.random_uniform([ 20, WEIGHT_SIZE],  minval=-0.2,maxval=0.2))\n",
    "\n",
    "o_hv = tf.nn.tanh(tf.matmul(x1_input, o_Wv))\n",
    "o_ht = tf.nn.tanh(tf.matmul(x2_input, o_Wt))\n",
    "o_hd = tf.nn.tanh(tf.matmul(x3_input, o_Wd))\n",
    "\n",
    "o_vt = tf.nn.relu(tf.matmul(tf.concat((x1_input,x2_input), axis=1), o_Wvt))\n",
    "o_vd = tf.nn.relu(tf.matmul(tf.concat((x1_input,x3_input), axis=1), o_Wvd)) \n",
    "o_td = tf.nn.relu(tf.matmul(tf.concat((x2_input,x3_input), axis=1), o_Wtd))\n",
    "\n",
    "o_Hvt = tf.multiply(o_vt, o_hv) + tf.multiply((1-o_vt), o_ht)\n",
    "o_Hvd = tf.multiply(o_vd, o_hv) + tf.multiply((1-o_vd), o_hd)\n",
    "o_Htd = tf.multiply(o_td, o_ht) + tf.multiply((1-o_td), o_hd)\n",
    "\n",
    "\n",
    "if(WEIGHT_SIZE == 10):\n",
    "    # GN2_10\n",
    "    if(FUSION == 2):\n",
    "        o_h = tf.nn.softmax(o_Hvt + o_Htd) \n",
    "    # GN3_10\n",
    "    else:\n",
    "        o_h = tf.nn.softmax(o_Hvt + o_Htd + o_Hvd)  \n",
    "else:\n",
    "    concatSize = 0\n",
    "    if(FUSION == 2):\n",
    "        # 2 fuse 50\n",
    "        concatSize = 100\n",
    "        o_h_temp = tf.concat([o_Hvt,o_Htd],axis=1)\n",
    "    else:\n",
    "        # 3 fuse 50\n",
    "        concatSize = 150\n",
    "        o_h_temp = tf.concat([o_Hvt,o_Htd, o_Hvd],axis=1)\n",
    "\n",
    "    W13  = tf.Variable(tf.random_uniform([concatSize, 256],  minval=-0.2,maxval=0.2))\n",
    "    B13 =  tf.Variable(tf.random_normal([256], mean=0.1,stddev=.1))\n",
    "    W23  = tf.Variable(tf.random_uniform([256, 64],  minval=-0.2,maxval=0.2))\n",
    "    B23 =  tf.Variable(tf.random_normal([64], mean=0.1,stddev=.1))\n",
    "    W33  = tf.Variable(tf.random_uniform([64, 10],  minval=-0.2,maxval=0.2))\n",
    "    B33 =  tf.Variable(tf.random_normal([10], mean=0.1,stddev=.1))\n",
    "\n",
    "    L13 =  tf.nn.relu(tf.add(tf.matmul(o_h_temp, W13), B13))\n",
    "    L13_dropout = tf.nn.dropout(L13,pkeep)\n",
    "\n",
    "    L23 =  tf.nn.relu(tf.add(tf.matmul(L13_dropout, W23), B23))\n",
    "    L23_dropout = tf.nn.dropout(L23,pkeep)\n",
    "\n",
    "    o_h3 =  tf.add(tf.matmul(L23_dropout, W33), B33)\n",
    "    o_h = tf.nn.softmax(o_h3)  \n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=o_h, labels=y_label)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy) * 100\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(o_h, 1), tf.argmax(y_label, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    maxEpoch, maxValid = 0,0\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        dropout = 0.5\n",
    "        sess.run(train_step, feed_dict={x1_input: x1, x2_input: x2, x3_input: x3,\n",
    "                                                              y_label: y,  pkeep: dropout})\n",
    "\n",
    "        vacc = sess.run(accuracy, feed_dict={x1_input: x1_test, x2_input: x2_test, x3_input: x3_test, \n",
    "                                             y_label: y_test, pkeep: dropout})\n",
    "        if(vacc >maxValid):\n",
    "            maxEpoch = epoch\n",
    "            maxValid = vacc\n",
    "    gn_name = \"GN\"+str(FUSION)+\"_\"+str(WEIGHT_SIZE)\n",
    "    print(gn_name, \"for\",ac,ic,tc, \"got max accuracy at epoch\",maxEpoch,\" was:\",maxValid*100)\n",
    "\n",
    "print(\"Training done - took %s seconds\" % (time.time() - start_time)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for GN3_50 for all combinations of accuracy\n",
      "GN3_50 for 0.7 0.7 0.7 got max accuracy at epoch 938  was: 98.6475050449\n",
      "GN3_50 for 0.7 0.7 0.8 got max accuracy at epoch 959  was: 98.9856302738\n",
      "GN3_50 for 0.7 0.7 0.9 got max accuracy at epoch 973  was: 99.1265118122\n",
      "GN3_50 for 0.7 0.8 0.7 got max accuracy at epoch 439  was: 99.0983366966\n",
      "GN3_50 for 0.7 0.8 0.8 got max accuracy at epoch 610  was: 99.2955744267\n",
      "GN3_50 for 0.7 0.8 0.9 got max accuracy at epoch 967  was: 99.4082868099\n",
      "GN3_50 for 0.7 0.9 0.7 got max accuracy at epoch 963  was: 99.3801057339\n",
      "GN3_50 for 0.7 0.9 0.8 got max accuracy at epoch 440  was: 99.5491683483\n",
      "GN3_50 for 0.7 0.9 0.9 got max accuracy at epoch 479  was: 99.5491683483\n",
      "GN3_50 for 0.8 0.7 0.7 got max accuracy at epoch 961  was: 99.0983366966\n",
      "GN3_50 for 0.8 0.7 0.8 got max accuracy at epoch 810  was: 99.2392241955\n",
      "GN3_50 for 0.8 0.7 0.9 got max accuracy at epoch 589  was: 99.2392241955\n",
      "GN3_50 for 0.8 0.8 0.7 got max accuracy at epoch 965  was: 99.3237555027\n",
      "GN3_50 for 0.8 0.8 0.8 got max accuracy at epoch 661  was: 99.4082868099\n",
      "GN3_50 for 0.8 0.8 0.9 got max accuracy at epoch 922  was: 99.5209932327\n",
      "GN3_50 for 0.8 0.9 0.7 got max accuracy at epoch 948  was: 99.5209932327\n",
      "GN3_50 for 0.8 0.9 0.8 got max accuracy at epoch 420  was: 99.6055245399\n",
      "GN3_50 for 0.8 0.9 0.9 got max accuracy at epoch 479  was: 99.7182309628\n",
      "GN3_50 for 0.9 0.7 0.7 got max accuracy at epoch 949  was: 98.7038612366\n",
      "GN3_50 for 0.9 0.7 0.8 got max accuracy at epoch 912  was: 98.9574551582\n",
      "GN3_50 for 0.9 0.7 0.9 got max accuracy at epoch 839  was: 98.9010989666\n",
      "GN3_50 for 0.9 0.8 0.7 got max accuracy at epoch 758  was: 98.8165676594\n",
      "GN3_50 for 0.9 0.8 0.8 got max accuracy at epoch 819  was: 99.0419864655\n",
      "GN3_50 for 0.9 0.8 0.9 got max accuracy at epoch 968  was: 99.1546928883\n",
      "GN3_50 for 0.9 0.9 0.7 got max accuracy at epoch 840  was: 99.070161581\n",
      "GN3_50 for 0.9 0.9 0.8 got max accuracy at epoch 934  was: 99.2110431194\n",
      "GN3_50 for 0.9 0.9 0.9 got max accuracy at epoch 931  was: 99.2392241955\n"
     ]
    }
   ],
   "source": [
    "### GATING NETWORK\n",
    "\n",
    "testNetworks_f = [3]\n",
    "testNetworks_w = [50]\n",
    "\n",
    "print(\"Start training for GN3_50 for all combinations of accuracy\")\n",
    "\n",
    "for fuse in testNetworks_f:\n",
    "    for weight in testNetworks_w:\n",
    "        \n",
    "\n",
    "        FUSION = fuse\n",
    "        WEIGHT_SIZE = weight\n",
    "\n",
    "        for ac in ac_sets:\n",
    "            for ic in ic_sets:\n",
    "                for tc in tc_sets:\n",
    "                    trainingSet, validationSet = loadData_ThreeModal(ac,ic,tc)\n",
    "                    reset_graph()\n",
    "\n",
    "                    trainingSet, validationSet = loadData_ThreeModal(ac,ic,tc)\n",
    "\n",
    "                    pkeep = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "                    # 10 features\n",
    "                    x1 = [row[0] for row in trainingSet] \n",
    "                    x2 = [row[1] for row in trainingSet] \n",
    "                    x3 = [row[2] for row in trainingSet] \n",
    "                    y =  [row[3] for row in trainingSet] \n",
    "\n",
    "                    x1_test = [row[0] for row in validationSet] \n",
    "                    x2_test = [row[1] for row in validationSet] \n",
    "                    x3_test = [row[2] for row in validationSet] \n",
    "                    y_test =  [row[3] for row in validationSet] \n",
    "\n",
    "                    x1_input = tf.placeholder(tf.float32, [None, 10])\n",
    "                    x2_input = tf.placeholder(tf.float32, [None, 10])\n",
    "                    x3_input = tf.placeholder(tf.float32, [None, 10])\n",
    "                    y_label = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "                    # Other method according to paper\n",
    "                    o_Wv = tf.Variable(tf.random_uniform([ 10, WEIGHT_SIZE],  minval=-0.2,maxval=0.2))\n",
    "                    o_Wt = tf.Variable(tf.random_uniform([ 10, WEIGHT_SIZE],  minval=-0.2,maxval=0.2))\n",
    "                    o_Wd = tf.Variable(tf.random_uniform([ 10, WEIGHT_SIZE],  minval=-0.2,maxval=0.2))\n",
    "\n",
    "                    o_Wvt = tf.Variable(tf.random_uniform([ 20, WEIGHT_SIZE],  minval=-0.2,maxval=0.2))\n",
    "                    o_Wvd = tf.Variable(tf.random_uniform([ 20, WEIGHT_SIZE],  minval=-0.2,maxval=0.2))\n",
    "                    o_Wtd = tf.Variable(tf.random_uniform([ 20, WEIGHT_SIZE],  minval=-0.2,maxval=0.2))\n",
    "\n",
    "                    o_hv = tf.nn.tanh(tf.matmul(x1_input, o_Wv))\n",
    "                    o_ht = tf.nn.tanh(tf.matmul(x2_input, o_Wt))\n",
    "                    o_hd = tf.nn.tanh(tf.matmul(x3_input, o_Wd))\n",
    "\n",
    "                    o_vt = tf.nn.relu(tf.matmul(tf.concat((x1_input,x2_input), axis=1), o_Wvt))\n",
    "                    o_vd = tf.nn.relu(tf.matmul(tf.concat((x1_input,x3_input), axis=1), o_Wvd)) \n",
    "                    o_td = tf.nn.relu(tf.matmul(tf.concat((x2_input,x3_input), axis=1), o_Wtd))\n",
    "\n",
    "                    o_Hvt = tf.multiply(o_vt, o_hv) + tf.multiply((1-o_vt), o_ht)\n",
    "                    o_Hvd = tf.multiply(o_vd, o_hv) + tf.multiply((1-o_vd), o_hd)\n",
    "                    o_Htd = tf.multiply(o_td, o_ht) + tf.multiply((1-o_td), o_hd)\n",
    "\n",
    "\n",
    "                    if(WEIGHT_SIZE == 10):\n",
    "                        # GN2_10\n",
    "                        if(FUSION == 2):\n",
    "                            o_h = tf.nn.softmax(o_Hvt + o_Htd) \n",
    "                        # GN3_10\n",
    "                        else:\n",
    "                            o_h = tf.nn.softmax(o_Hvt + o_Htd + o_Hvd)  \n",
    "                    else:\n",
    "                        concatSize = 0\n",
    "                        if(FUSION == 2):\n",
    "                            # 2 fuse 50\n",
    "                            concatSize = 100\n",
    "                            o_h_temp = tf.concat([o_Hvt,o_Htd],axis=1)\n",
    "                        else:\n",
    "                            # 3 fuse 50\n",
    "                            concatSize = 150\n",
    "                            o_h_temp = tf.concat([o_Hvt,o_Htd, o_Hvd],axis=1)\n",
    "\n",
    "                        W13  = tf.Variable(tf.random_uniform([concatSize, 256],  minval=-0.2,maxval=0.2))\n",
    "                        B13 =  tf.Variable(tf.random_normal([256], mean=0.1,stddev=.1))\n",
    "                        W23  = tf.Variable(tf.random_uniform([256, 64],  minval=-0.2,maxval=0.2))\n",
    "                        B23 =  tf.Variable(tf.random_normal([64], mean=0.1,stddev=.1))\n",
    "                        W33  = tf.Variable(tf.random_uniform([64, 10],  minval=-0.2,maxval=0.2))\n",
    "                        B33 =  tf.Variable(tf.random_normal([10], mean=0.1,stddev=.1))\n",
    "\n",
    "                        L13 =  tf.nn.relu(tf.add(tf.matmul(o_h_temp, W13), B13))\n",
    "                        L13_dropout = tf.nn.dropout(L13,pkeep)\n",
    "\n",
    "                        L23 =  tf.nn.relu(tf.add(tf.matmul(L13_dropout, W23), B23))\n",
    "                        L23_dropout = tf.nn.dropout(L23,pkeep)\n",
    "\n",
    "                        o_h3 =  tf.add(tf.matmul(L23_dropout, W33), B33)\n",
    "                        o_h = tf.nn.softmax(o_h3)  \n",
    "\n",
    "                    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=o_h, labels=y_label)\n",
    "                    cross_entropy = tf.reduce_mean(cross_entropy) * 100\n",
    "\n",
    "                    optimizer = tf.train.AdamOptimizer()\n",
    "                    train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "                    correct_pred = tf.equal(tf.argmax(o_h, 1), tf.argmax(y_label, 1))\n",
    "                    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "                    init = tf.global_variables_initializer()\n",
    "\n",
    "                    epochs = 1000\n",
    "\n",
    "                    t_acc = []\n",
    "                    v_acc = []\n",
    "\n",
    "                    gn_t_pred = []\n",
    "                    gn_v_pred = []\n",
    "\n",
    "                    with tf.Session() as sess:\n",
    "                        sess.run(init)\n",
    "\n",
    "                        maxEpoch, maxValid = 0,0\n",
    "                        for epoch in range(epochs):\n",
    "\n",
    "                            dropout = 0.5\n",
    "                            #currValidLoss, currValidAcc = sess.run([cost,accuracy], feed_dict={x: batch_x, y: batch_y, keep_prob: 1.})\n",
    "                            _, tacc = sess.run([train_step, accuracy], feed_dict={x1_input: x1, x2_input: x2, x3_input: x3,\n",
    "                                                                                  y_label: y,  pkeep: dropout})\n",
    "                            t_acc.append(tacc)\n",
    "                            #print(\"epoch\",epoch)\n",
    "                            #print(\"train acc\", tacc)\n",
    "\n",
    "                            vacc = sess.run(accuracy, feed_dict={x1_input: x1_test, x2_input: x2_test, x3_input: x3_test, \n",
    "                                                                 y_label: y_test, pkeep: dropout})\n",
    "                            v_acc.append(vacc)\n",
    "                            #print(\"valid acc\", vacc)\n",
    "                            if(vacc >maxValid):\n",
    "                                maxEpoch = epoch\n",
    "                                maxValid = vacc\n",
    "                        gn_name = \"GN\"+str(FUSION)+\"_\"+str(WEIGHT_SIZE)\n",
    "                        print(gn_name, \"for\",ac,ic,tc, \"got max accuracy at epoch\",maxEpoch,\" was:\",maxValid*100)\n",
    "                        #tt = sess.run(o_h, feed_dict={x1_input: x1, x2_input: x2, x3_input: x3, y_label: y, pkeep:1})\n",
    "                        #vv = sess.run(o_h, feed_dict={x1_input: x1_test, x2_input: x2_test,  x3_input: x3_test, y_label: y_test,pkeep:1})\n",
    "                        #gn_t_pred = tt\n",
    "                        #gn_v_pred = vv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### EXPENSIVE RUN HERE - RUN ALL POSSIBLE COMBINATIONS FOR AC,IC, AND TC IN 70,80,90 % ACCURACY\n",
    "#### THIS IS DONE FOR ALL METHODS, RUNNING 8*3*3 = 72 CLASSIFICATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Training MLP of AC,IC,TC 0.9 0.9 0.9 Accuracy at max epoch 925 : 99.5210\n",
      "Training done - took 216.78330206871033 seconds\n"
     ]
    }
   ],
   "source": [
    "# Training time for MLP\n",
    "import math \n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "trainingSet, validationSet = loadData_ThreeModal(\"0.9\",\"0.9\",\"0.9\")\n",
    "\n",
    "x1_10_mlp = [row[0] for row in trainingSet]\n",
    "x2_10_mlp = [row[1] for row in trainingSet]\n",
    "x3_10_mlp = [row[2] for row in trainingSet]\n",
    "\n",
    "y_mlp =     [row[3] for row in trainingSet]  \n",
    "\n",
    "xt_10_mlp_concat = np.concatenate((x1_10_mlp, x2_10_mlp,x3_10_mlp),axis=1)\n",
    "\n",
    "x1_10_mlp_test = [row[0] for row in validationSet]\n",
    "x2_10_mlp_test = [row[1] for row in validationSet]\n",
    "x3_10_mlp_test = [row[2] for row in validationSet]\n",
    "\n",
    "y_mlp_test =     [row[3] for row in validationSet]\n",
    "\n",
    "xv_10_mlp_concat_test = np.concatenate((x1_10_mlp_test, x2_10_mlp_test,x3_10_mlp_test),axis=1)\n",
    "reset_graph()\n",
    "\n",
    "\n",
    "# MLP\n",
    "X = tf.placeholder(tf.float32, [None, 30])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "aLearningRate = tf.placeholder(tf.float32, shape=[])\n",
    "pkeep = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "max_learning_rate = 0.005\n",
    "min_learning_rate = 0.0001\n",
    "decay_speed = 2000.0\n",
    "\n",
    "W1  = tf.Variable(tf.random_uniform([30, 60],  minval=-0.2,maxval=0.2))\n",
    "B1 =  tf.Variable(tf.random_normal([60], mean=0.1,stddev=.1))\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([60, 40],  minval=-0.2,maxval=0.2))\n",
    "B2 = tf.Variable(tf.random_normal([40], mean=0.1,stddev=.1))\n",
    "\n",
    "W3 = tf.Variable(tf.random_uniform([40, 25],  minval=-0.2,maxval=0.2))\n",
    "B3 = tf.Variable(tf.random_normal([25], mean=0.1,stddev=.1))\n",
    "\n",
    "W4 = tf.Variable(tf.random_uniform([25, 10],  minval=-0.2,maxval=0.2))\n",
    "B4 = tf.Variable(tf.random_normal([10], mean=0.1,stddev=.1))\n",
    "\n",
    "Y1_hat =tf.nn.relu(tf.add(tf.matmul(X, W1), B1))\n",
    "Y1_hat_dropout = tf.nn.dropout(Y1_hat,pkeep)\n",
    "\n",
    "Y2_hat =  tf.nn.relu(tf.add(tf.matmul(Y1_hat_dropout, W2), B2)) \n",
    "Y2_hat_dropout = tf.nn.dropout(Y2_hat,pkeep)\n",
    "\n",
    "Y3_hat =  tf.nn.relu(tf.add(tf.matmul(Y2_hat_dropout, W3), B3)) \n",
    "Y3_hat_dropout = tf.nn.dropout(Y3_hat,pkeep)\n",
    "\n",
    "Y4_hat =  tf.nn.relu(tf.add(tf.matmul(Y3_hat_dropout, W4), B4)) \n",
    "Y_hat = tf.nn.softmax(Y4_hat)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Y_hat, labels=Y)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy) * 100\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=aLearningRate)\n",
    "train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_hat, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "n_epochs = 1000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    maxEpoch, maxValid = 0,0\n",
    "\n",
    "    dropout = 0.5\n",
    "    # train\n",
    "    for epoch in range(n_epochs):\n",
    "        learning_rate = min_learning_rate+(max_learning_rate - min_learning_rate) * math.exp((-1*epoch)/2000)\n",
    "        sess.run(train_step, feed_dict={X: xt_10_mlp_concat, Y: y_mlp, aLearningRate: learning_rate, pkeep:dropout})\n",
    "        #accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        acc = sess.run(accuracy, feed_dict={X: xv_10_mlp_concat_test, Y: y_mlp_test, pkeep:1})\n",
    "        if(acc >maxValid):\n",
    "            maxEpoch = epoch\n",
    "            maxValid = acc\n",
    "    print(\"Done Training MLP of AC,IC,TC 0.9 0.9 0.9 Accuracy at max epoch\",maxEpoch,\": %.4f\" % (100*maxValid))\n",
    "print(\"Training done - took %s seconds\" % (time.time() - start_time)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Training MLP of AC,IC,TC 0.7 0.7 0.7  Accuracy at max epoch 378 : 98.7039\n",
      "Done Training MLP of AC,IC,TC 0.7 0.7 0.8  Accuracy at max epoch 307 : 99.0138\n",
      "Done Training MLP of AC,IC,TC 0.7 0.7 0.9  Accuracy at max epoch 382 : 99.0983\n",
      "Done Training MLP of AC,IC,TC 0.7 0.8 0.7  Accuracy at max epoch 671 : 99.0983\n",
      "Done Training MLP of AC,IC,TC 0.7 0.8 0.8  Accuracy at max epoch 415 : 99.3238\n",
      "Done Training MLP of AC,IC,TC 0.7 0.8 0.9  Accuracy at max epoch 281 : 99.4365\n",
      "Done Training MLP of AC,IC,TC 0.7 0.9 0.7  Accuracy at max epoch 692 : 99.3801\n",
      "Done Training MLP of AC,IC,TC 0.7 0.9 0.8  Accuracy at max epoch 654 : 99.5210\n",
      "Done Training MLP of AC,IC,TC 0.7 0.9 0.9  Accuracy at max epoch 382 : 99.4083\n",
      "Done Training MLP of AC,IC,TC 0.8 0.7 0.7  Accuracy at max epoch 537 : 99.0702\n",
      "Done Training MLP of AC,IC,TC 0.8 0.7 0.8  Accuracy at max epoch 482 : 99.3238\n",
      "Done Training MLP of AC,IC,TC 0.8 0.7 0.9  Accuracy at max epoch 922 : 99.2392\n",
      "Done Training MLP of AC,IC,TC 0.8 0.8 0.7  Accuracy at max epoch 959 : 99.2956\n",
      "Done Training MLP of AC,IC,TC 0.8 0.8 0.8  Accuracy at max epoch 664 : 99.3801\n",
      "Done Training MLP of AC,IC,TC 0.8 0.8 0.9  Accuracy at max epoch 272 : 99.4365\n",
      "Done Training MLP of AC,IC,TC 0.8 0.9 0.7  Accuracy at max epoch 806 : 99.4083\n",
      "Done Training MLP of AC,IC,TC 0.8 0.9 0.8  Accuracy at max epoch 312 : 99.4646\n",
      "Done Training MLP of AC,IC,TC 0.8 0.9 0.9  Accuracy at max epoch 924 : 99.6055\n",
      "Done Training MLP of AC,IC,TC 0.9 0.7 0.7  Accuracy at max epoch 970 : 98.8166\n",
      "Done Training MLP of AC,IC,TC 0.9 0.7 0.8  Accuracy at max epoch 909 : 99.2392\n",
      "Done Training MLP of AC,IC,TC 0.9 0.7 0.9  Accuracy at max epoch 557 : 99.1829\n",
      "Done Training MLP of AC,IC,TC 0.9 0.8 0.7  Accuracy at max epoch 827 : 99.1829\n",
      "Done Training MLP of AC,IC,TC 0.9 0.8 0.8  Accuracy at max epoch 885 : 99.3238\n",
      "Done Training MLP of AC,IC,TC 0.9 0.8 0.9  Accuracy at max epoch 824 : 99.4365\n",
      "Done Training MLP of AC,IC,TC 0.9 0.9 0.7  Accuracy at max epoch 928 : 99.3801\n",
      "Done Training MLP of AC,IC,TC 0.9 0.9 0.8  Accuracy at max epoch 821 : 99.3519\n",
      "Done Training MLP of AC,IC,TC 0.9 0.9 0.9  Accuracy at max epoch 925 : 99.5210\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "for ac in ac_sets:\n",
    "    for ic in ic_sets:\n",
    "        for tc in tc_sets:\n",
    "            trainingSet, validationSet = loadData_ThreeModal(ac,ic,tc)\n",
    "\n",
    "            x1_10_mlp = [row[0] for row in trainingSet]\n",
    "            x2_10_mlp = [row[1] for row in trainingSet]\n",
    "            x3_10_mlp = [row[2] for row in trainingSet]\n",
    "\n",
    "            y_mlp =     [row[3] for row in trainingSet]  \n",
    "\n",
    "            xt_10_mlp_concat = np.concatenate((x1_10_mlp, x2_10_mlp,x3_10_mlp),axis=1)\n",
    "\n",
    "            x1_10_mlp_test = [row[0] for row in validationSet]\n",
    "            x2_10_mlp_test = [row[1] for row in validationSet]\n",
    "            x3_10_mlp_test = [row[2] for row in validationSet]\n",
    "\n",
    "            y_mlp_test =     [row[3] for row in validationSet]\n",
    "\n",
    "            xv_10_mlp_concat_test = np.concatenate((x1_10_mlp_test, x2_10_mlp_test,x3_10_mlp_test),axis=1)\n",
    "            reset_graph()\n",
    "            \n",
    "\n",
    "            # MLP\n",
    "            X = tf.placeholder(tf.float32, [None, 30])\n",
    "            Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "            aLearningRate = tf.placeholder(tf.float32, shape=[])\n",
    "            pkeep = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "            max_learning_rate = 0.005\n",
    "            min_learning_rate = 0.0001\n",
    "            decay_speed = 2000.0\n",
    "\n",
    "            W1  = tf.Variable(tf.random_uniform([30, 60],  minval=-0.2,maxval=0.2))\n",
    "            B1 =  tf.Variable(tf.random_normal([60], mean=0.1,stddev=.1))\n",
    "\n",
    "            W2 = tf.Variable(tf.random_uniform([60, 40],  minval=-0.2,maxval=0.2))\n",
    "            B2 = tf.Variable(tf.random_normal([40], mean=0.1,stddev=.1))\n",
    "\n",
    "            W3 = tf.Variable(tf.random_uniform([40, 25],  minval=-0.2,maxval=0.2))\n",
    "            B3 = tf.Variable(tf.random_normal([25], mean=0.1,stddev=.1))\n",
    "\n",
    "            W4 = tf.Variable(tf.random_uniform([25, 10],  minval=-0.2,maxval=0.2))\n",
    "            B4 = tf.Variable(tf.random_normal([10], mean=0.1,stddev=.1))\n",
    "\n",
    "            Y1_hat =tf.nn.relu(tf.add(tf.matmul(X, W1), B1))\n",
    "            Y1_hat_dropout = tf.nn.dropout(Y1_hat,pkeep)\n",
    "\n",
    "            Y2_hat =  tf.nn.relu(tf.add(tf.matmul(Y1_hat_dropout, W2), B2)) \n",
    "            Y2_hat_dropout = tf.nn.dropout(Y2_hat,pkeep)\n",
    "\n",
    "            Y3_hat =  tf.nn.relu(tf.add(tf.matmul(Y2_hat_dropout, W3), B3)) \n",
    "            Y3_hat_dropout = tf.nn.dropout(Y3_hat,pkeep)\n",
    "\n",
    "            Y4_hat =  tf.nn.relu(tf.add(tf.matmul(Y3_hat_dropout, W4), B4)) \n",
    "            Y_hat = tf.nn.softmax(Y4_hat)\n",
    "\n",
    "            cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Y_hat, labels=Y)\n",
    "            cross_entropy = tf.reduce_mean(cross_entropy) * 100\n",
    "\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=aLearningRate)\n",
    "            train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "            correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_hat, 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "            init = tf.global_variables_initializer()\n",
    "\n",
    "            n_epochs = 1000\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(init)\n",
    "                maxEpoch, maxValid = 0,0\n",
    "\n",
    "                dropout = 0.5\n",
    "                # train\n",
    "                for epoch in range(n_epochs):\n",
    "                    learning_rate = min_learning_rate+(max_learning_rate - min_learning_rate) * math.exp((-1*epoch)/2000)\n",
    "                    sess.run(train_step, feed_dict={X: xt_10_mlp_concat, Y: y_mlp, aLearningRate: learning_rate, pkeep:dropout})\n",
    "                    #accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "                    acc = sess.run(accuracy, feed_dict={X: xv_10_mlp_concat_test, Y: y_mlp_test, pkeep:1})\n",
    "                    if(acc >maxValid):\n",
    "                        maxEpoch = epoch\n",
    "                        maxValid = acc\n",
    "                print(\"Done Training MLP of AC,IC,TC\",ac,ic,tc,\" Accuracy at max epoch\",maxEpoch,\": %.4f\" % (100*maxValid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Training SVM of AC,IC,TC 0.9 0.9 0.9 Accuracy: 98.82\n",
      "Training done - took 6.760161876678467 seconds\n"
     ]
    }
   ],
   "source": [
    "# Training time for SVM\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "trainingSet, validationSet = loadData_ThreeModal(\"0.9\",\"0.9\",\"0.9\")\n",
    "\n",
    "x1_10_svm = [row[0] for row in trainingSet]\n",
    "x2_10_svm = [row[1] for row in trainingSet]\n",
    "x3_10_svm = [row[2] for row in trainingSet]\n",
    "\n",
    "y_svm =     [np.argmax(row[3]) for row in trainingSet]  \n",
    "xt_10_svm_concat = np.concatenate((x1_10_svm, x2_10_svm,x3_10_svm),axis=1)\n",
    "\n",
    "x1_10_svm_test = [row[0] for row in validationSet]\n",
    "x2_10_svm_test = [row[1] for row in validationSet]\n",
    "x3_10_svm_test = [row[2] for row in validationSet]\n",
    "\n",
    "y_svm_test =     [np.argmax(row[3]) for row in validationSet]\n",
    "xv_10_svm_concat_test = np.concatenate((x1_10_svm_test, x2_10_svm_test,x3_10_svm_test),axis=1)\n",
    "\n",
    "model_10_svc = svm.SVC(probability=True, kernel='linear', gamma= 0.001, C= 0.1, decision_function_shape='ovo')\n",
    "model_10_svc.fit(xt_10_svm_concat, y_svm)\n",
    "ty_pred_10_svc = model_10_svc.predict(xt_10_svm_concat)\n",
    "y_pred_10_svc = model_10_svc.predict(xv_10_svm_concat_test)\n",
    "\n",
    "tacc_10_svc = accuracy_score(y_svm, ty_pred_10_svc)\n",
    "#print(\"Training accuracy: {:.4f}\".format(tacc_10_svc))\n",
    "\n",
    "vacc_10_svc = accuracy_score(y_svm_test, y_pred_10_svc)\n",
    "print(\"Done Training SVM of AC,IC,TC 0.9 0.9 0.9 Accuracy: {:.2f}\".format(vacc_10_svc*100))\n",
    "print(\"Training done - took %s seconds\" % (time.time() - start_time)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Training SVM of AC,IC,TC 0.7 0.7 0.7  Accuracy: 98.25\n",
      "Done Training SVM of AC,IC,TC 0.7 0.7 0.8  Accuracy: 98.56\n",
      "Done Training SVM of AC,IC,TC 0.7 0.7 0.9  Accuracy: 98.79\n",
      "Done Training SVM of AC,IC,TC 0.7 0.8 0.7  Accuracy: 98.76\n",
      "Done Training SVM of AC,IC,TC 0.7 0.8 0.8  Accuracy: 98.96\n",
      "Done Training SVM of AC,IC,TC 0.7 0.8 0.9  Accuracy: 99.07\n",
      "Done Training SVM of AC,IC,TC 0.7 0.9 0.7  Accuracy: 98.79\n",
      "Done Training SVM of AC,IC,TC 0.7 0.9 0.8  Accuracy: 99.24\n",
      "Done Training SVM of AC,IC,TC 0.7 0.9 0.9  Accuracy: 99.15\n",
      "Done Training SVM of AC,IC,TC 0.8 0.7 0.7  Accuracy: 98.82\n",
      "Done Training SVM of AC,IC,TC 0.8 0.7 0.8  Accuracy: 98.96\n",
      "Done Training SVM of AC,IC,TC 0.8 0.7 0.9  Accuracy: 99.27\n",
      "Done Training SVM of AC,IC,TC 0.8 0.8 0.7  Accuracy: 99.04\n",
      "Done Training SVM of AC,IC,TC 0.8 0.8 0.8  Accuracy: 99.21\n",
      "Done Training SVM of AC,IC,TC 0.8 0.8 0.9  Accuracy: 99.38\n",
      "Done Training SVM of AC,IC,TC 0.8 0.9 0.7  Accuracy: 99.13\n",
      "Done Training SVM of AC,IC,TC 0.8 0.9 0.8  Accuracy: 99.27\n",
      "Done Training SVM of AC,IC,TC 0.8 0.9 0.9  Accuracy: 99.44\n",
      "Done Training SVM of AC,IC,TC 0.9 0.7 0.7  Accuracy: 98.28\n",
      "Done Training SVM of AC,IC,TC 0.9 0.7 0.8  Accuracy: 98.37\n",
      "Done Training SVM of AC,IC,TC 0.9 0.7 0.9  Accuracy: 98.51\n",
      "Done Training SVM of AC,IC,TC 0.9 0.8 0.7  Accuracy: 98.22\n",
      "Done Training SVM of AC,IC,TC 0.9 0.8 0.8  Accuracy: 98.37\n",
      "Done Training SVM of AC,IC,TC 0.9 0.8 0.9  Accuracy: 98.62\n",
      "Done Training SVM of AC,IC,TC 0.9 0.9 0.7  Accuracy: 98.62\n",
      "Done Training SVM of AC,IC,TC 0.9 0.9 0.8  Accuracy: 98.65\n",
      "Done Training SVM of AC,IC,TC 0.9 0.9 0.9  Accuracy: 98.82\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for ac in ac_sets:\n",
    "    for ic in ic_sets:\n",
    "        for tc in tc_sets:\n",
    "            trainingSet, validationSet = loadData_ThreeModal(ac,ic,tc)\n",
    "\n",
    "            x1_10_svm = [row[0] for row in trainingSet]\n",
    "            x2_10_svm = [row[1] for row in trainingSet]\n",
    "            x3_10_svm = [row[2] for row in trainingSet]\n",
    "\n",
    "            y_svm =     [np.argmax(row[3]) for row in trainingSet]  \n",
    "            xt_10_svm_concat = np.concatenate((x1_10_svm, x2_10_svm,x3_10_svm),axis=1)\n",
    "\n",
    "            x1_10_svm_test = [row[0] for row in validationSet]\n",
    "            x2_10_svm_test = [row[1] for row in validationSet]\n",
    "            x3_10_svm_test = [row[2] for row in validationSet]\n",
    "            \n",
    "            y_svm_test =     [np.argmax(row[3]) for row in validationSet]\n",
    "            xv_10_svm_concat_test = np.concatenate((x1_10_svm_test, x2_10_svm_test,x3_10_svm_test),axis=1)\n",
    "\n",
    "            model_10_svc = svm.SVC(probability=True, kernel='linear', gamma= 0.001, C= 0.1, decision_function_shape='ovo')\n",
    "            model_10_svc.fit(xt_10_svm_concat, y_svm)\n",
    "            ty_pred_10_svc = model_10_svc.predict(xt_10_svm_concat)\n",
    "            y_pred_10_svc = model_10_svc.predict(xv_10_svm_concat_test)\n",
    "\n",
    "            tacc_10_svc = accuracy_score(y_svm, ty_pred_10_svc)\n",
    "            #print(\"Training accuracy: {:.4f}\".format(tacc_10_svc))\n",
    "\n",
    "            vacc_10_svc = accuracy_score(y_svm_test, y_pred_10_svc)\n",
    "            print(\"Done Training SVM of AC,IC,TC\",ac,ic,tc,\" Accuracy: {:.2f}\".format(vacc_10_svc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct samples: 3519 ( 0.9915469146238377 )\n",
      "Incorrect samples: 30 ( 0.0084530853761623 )\n"
     ]
    }
   ],
   "source": [
    "# See uncorrect labels at 0.9 0.9 0.9 for GN3_50\n",
    "correct_samples = []\n",
    "incorrect_samples = []\n",
    "y_label = [np.argmax(row[3]) for row in validationSet]\n",
    "for i in range(len(validationSet)):\n",
    "    if(y_label[i] != placehold[i]):\n",
    "        incorrect_samples.append([i,placehold[i]])\n",
    "    else:\n",
    "        correct_samples.append([i,placehold[i]])\n",
    "        \n",
    "print(\"Correct samples:\",len(correct_samples),\"(\", (len(correct_samples) / len(validationSet)),\")\")\n",
    "print(\"Incorrect samples:\",len(incorrect_samples),\"(\",(len(incorrect_samples) / len(validationSet)),\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUNCTION TO DISPLAY A SAMPLE OF AUDIO, IMAGE, AND TEXTUAL DESCRIPTION\n",
    "#Display_Training_Data = pickle.load(open('data/Training_MMNIST.p', mode='rb'))\n",
    "Display_Validation_Data = pickle.load(open('data/Validation_MMNIST.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing sample number 1730\n",
      "Prediction - GN 8 AC 4 IC 7 TC 8\n",
      "Real label 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/EBQhB8I6v8BnPWC74oNMh0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ed809aceb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApgAAAEYCAYAAAD4aYaMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XucXXV57/Hvdyb3AHIJiQGKqGA1iqJGaIUCarUeW4uo\nWHq8gNXS9khbOcce8fS8NFT7Km1tkVdF2hwqcnpTWkU4WvGCRiogECDc5CYKCgnkAklIMslc9nP+\n2GvqZpjJrCdZa9/m8+a1XtmXZ6/5zWLPnmee380RIQAAAKAqA51uAAAAAPoLCSYAAAAqRYIJAACA\nSpFgAgAAoFIkmAAAAKgUCSYAAAAqRYIJAADQx2wfaPubth8o/j2gxGs+Z/vtxe1Vtu+zvcb2PbbP\nmu71JJgAAAB9wPbJtj83yVPnSromIo6SdE1xP+udEXGMpOMl/bntObsLJsEEAADob6dIuqy4fZmk\nt0wMcNOni0rltyQtnuJc+0jaLmlsd19w1l40tqvZZosiAAAwmY0RcXAnG/Arv3JsbNq0pVTsLbfc\nf7eknS0PrYyIlYkvtyQi1hW3H5O0ZJKYUyX9vKRlxfM/kPTZluf/yfYuSUdJ+mBEzMwEs6nPvz0A\nALAHRh/udAs2bdqiG2/6u1KxswZfszMilk/1vO0bJc1Vs7p4oO01xVMfjoivt8ZGRExRhDtR0r8U\nieNa29+e8Pw7I2K17YMlXW/76oiY8jqSgQEAALRbSGo0qjlVxHFScwympDMj4swJIY/bXhoR62wv\nlbR+L77WBtu3SjpO0pQJJmMwAQAA2i6aCWaZY+9dJemM4vYZkq6cJOZaSb9he7BIQl8z2YlsL5D0\nckkP7u4LUsEEAADohIoqmCWcL+ly2+9Ts+r4jklirpD0WjXHXv5E0g0Tnv8n20NqdsV/LiJu2d0X\nJMEEAABotwhpbLfzZPbglLFK0qpJHt8k6XXTvDYknT3Fcydn20KCCQAA0Antq2C2HQkmAABAu1U4\nyacbkWACAAC0XZBgAgAAoEJUMAEAAFCtkIMEEwAAAFWiggkAAIDKhKTGZDs29gcSTAAAgLZjkg8A\nAACqFJLGRjvditqQYAIAALQdFUwAAABUiTGYAAAAqBYVTAAAAFSNBBMAAACVCckkmAAAAKhOSMEY\nTAAAAFSJCiYAAAAqEyLBBAAAQIUipNGxTreiNiSYAAAAnUAFEwAAANVhkg8AAACqxBhMAAAAVI6t\nIgEAAFAdtooEAABAlegiBwAAQOXoIgcAAEB1QgoqmAAAAKhKiAomAAAAKhRiJx8AAABUiVnkAAAA\nqBpd5AAAAKhMiEk+AAAAqFJQwQQAAEDFSDABAABQGXbyAQAAQOX6uII50OkGAAAAzDhRjMEscyTY\nfqHtG2zvsv2hkq850/ani9srbD9qe43te21fbDudL9aeYNoetH2b7a8U9w+0/U3bDxT/HlA8Psf2\npbbvtH277ZNbzjHH9krb9xff7NvqbjcAAECtxsbKHTlPSPoDSZ/ci5ZdEBHHSFom6WhJJ2VP0I4K\n5h9Kuqfl/rmSromIoyRdU9yXpN+WpIg4WtLrJf1VS8b8x5LWR8QL1Pxmv9uGdgMAANRjfKvIiiuY\nEbE+Im6WNLK7ONvvLQp3N0k6foqwOZLmSXoy1QjVnGDaPkzSr0q6pOXhUyRdVty+TNJbitvLJH1b\nal4cSZslLS+e+y1Jf1Y814iIjXW2GwAAoF6pLvJFtle3HGftzVe2vVTSeWomlieomYO1Osf2Gknr\nJN0fEWuyX6PuCuanJP1PSa3TpJZExLri9mOSlhS3b5f067Zn2X6upFdK+jnb+xfPf9z2rbb/1fYS\nTcL2WUXX+4bqvxUAAIAKNRrlDmljRCxvOVbu5Vc+TtKqiNgQEcOSvjDh+fEu8sWSFto+PfsFaksw\nbf+amt3at0wVExGhZpFYkj4r6RFJq9VMTK+XNKbmTPfDJF0fEa+QdIOmGFcQESsj4qiIOLiybwQA\nAKBqFXWR2/5AMSFnje1DKm1ixIikqyWdmH1tncsUHa9mRfJNavbf72f7HyU9bntpRKwrSrTrJSki\nRiWdM/5i29dLul/SJkk7JH2peOpfJb2vxnYDAADUr4JliiLiIkkXJV92o6QLbR8kaauk09TsSX4a\n21Yzn7st267aKpgR8ZGIOCwijpB0uqRvR8S7JF0l6Ywi7AxJV0qS7QW2Fxa3Xy9pNCJ+UFQ5/5+k\nk4vXvE7SD+pqNwAAQO3qW6bo2bYfkfTfJf1v24/Y3u/pXzrWSVqhZq/wdXr6ZGzpZ2Mw75I0KOkz\n2W+vEwutny/pctvvk/SwpHcUjy+W9HXbDUmPSnp3y2s+LOkfbH9K0gZJ721jewEAACoXNSy0HhGP\nqTm0cLq4SyVdOsnjK9RMPvdKWxLMiFglaVVxe5OaVciJMQ9J+vkpXv+w9qD/HwAAoGtF/+7kw1aR\nAAAA7TY+yadPkWACAAC0W4Q02pg+rkeRYAIAAHQCFUwAAABUqY5JPt2CBBMAAKDdGIMJAACAypFg\nAgAAoDKRX0S9l5BgAgAAdALrYAIAAKAqISn6d5UiEkwAAIC2Y5IPAAAAqhajJJgAAACoChVMAAAA\nVI4xmAAAAKhMBDv5AAAAoGJUMAEAAFCp/i1gkmACAAC0XYgucgAAAFSMLnIAAABUiZ18AAAAUJkI\nKUY73Yr6kGACAAC0W4gucgAAAFQr+neODwkmAABAJzAGEwAAANWhixwAAABVo4IJAACASjEGEwAA\nANUJSQ13uhW1IcEEAABosxBd5AAmYdX7l2eoj/tOAGDGsyKoYAKYgAQQALDHQmqwkw8AAACqEhIV\nTADPRBc5AGCPhRRM8gEwUTYBzCakJLAA0N/6eZmigU43AAAAYCaKcKkjw/Y7bd9h+07b19t+WYnX\nnGn708XtFbYftb3G9r22L7adzhdJMIFu5cHcAQDoKdFwqSPpx5JOioijJX1c0so9aNoFEXGMpGWS\njpZ0UvYEdJEDAAC0WUQ9XeQRcX3L3e9LOmyyONvvlfQRSZsl3S5p1yRhcyTNk/Rkth0kmMAeSo+R\nTFYZnYwPJVfs7efBPwDQ9VLd34tsr265vzIiylQm3yfpa8/4yvZSSedJeqWkLZK+I+m2lpBzbL9L\n0nMkfS0i1pRt6Ljausht/5zt79j+ge27bf9h8fiBtr9p+4Hi3wMmvO5w29tsf6jlsd8sxhLcYftq\n24vqajdmLif/S4ux1BGN4dwRjdQBAOisRsOlDkkbI2J5yzFtcmn7NWommB+e5OnjJK2KiA0RMSzp\nCxOeH+8iXyxpoe3Ts99bnWMwRyX9j4hYJukXJH3A9jJJ50q6JiKOknRNcb/VX6sl27Y9S9KFkl4T\nES+VdIeks2tsNwAAQK0iUgnmlGx/oJiQs8b2IcVjL5V0iaRTImLTnrcxRiRdLenE7GtrSzAjYl1E\n3FrcfkrSPZIOlXSKpMuKsMskvWX8Nbbfoubg1LtbTuXiWGjbkvaTtLaudgOl2bkjKZL/pZtfd8UW\nALBbVcwij4iLIuKY4lhr+3BJX5L07oi4f4qX3SjpJNsH2Z4t6bTJgoq863hJD2a/t7bMIrd9hKSX\nq/kNLYmIdcVTj0laUsTso2YZ97zW1xbZ8+9JulPNxHKZpL+f4uucVXS9b6j+uwAAAKhOI1zqSPqo\npIMkfaaoaq6eGFDkYSsk3SDpOjWLgK3Osb1G0l2SBiV9JtuI2if5FInjFyV9MCK2uqWSExFhe7z0\nskLNPv9trTFFZv17aiaoP5L0N2rOevrExK9VjElYWbyOGQxISVcBe3ySDAutA0AHxR4tQTT9aSPe\nL+n9JeIulXTpJI+vUDMn2yu1JphFcvhFSf8UEV8qHn7c9tKIWFfMYlpfPH6cpLfb/gtJ+0tq2N6p\nZtVTEfFgcc7L9cxxmwAAAD2juRd5p1tRn9oSzKLf/u8l3RMRf93y1FWSzpB0fvHvlZIUEb/U8toV\nkrZFxKeLAavLbB8cERskvV7PLOUCAAD0lD3o/u4ZdVYwj5f0bkl3Fv34kvS/1EwsL7f9PkkPS3rH\n7k5SDFg9T9K1tkeK15xZW6sBAADaILsNZC+pLcGMiO9JU049fd00r10x4f7fSvrbaloGAADQWSEq\nmAB6QN1LCTEpCO2QeR/znkRPCyqYAPoQv5zR6wYG5qbiI8aS8aOpeCCrn/dUI8EEAABos5A11mjL\ncuQdQYIJdCl2z8FMlKqsJyuS2XpR+mfQg7n4bEWVXoe+Qxc5gLbjlwkwjWyCmU0As7/7SRiR1Ojj\ntwAJJgAAQJsFk3wAAOg+2Qqg013qOVQkkdXo46FQJJgAAAAdwFaRAJ4hOwGA6gZQrV5f+7XX24+9\nEzILrQN4Jj68geqlkq7spJ3sqoPJ8hJ/dCKLLnIAAABUii5yAF2P6gn6QeZ9WfekHTu5CHY/Zwuo\nXEgaCxZaBwAAQFWCdTABAGiL3BjMXNXezu1dnhWxMxVPr8PMFhKTfAAAaIfcVpHJhCuZAGaRACLH\nij6e5FOq89/2L9lPn65n+xX1NAkAAKD/NaLc0YvKVjC/Lulm26dFxPrisUskkWQCJbHmHTA9u3zH\n2uxZ+6fOPTAwJxW/a3j99EGtYjQXjxlvxlcwJd0n6S8lfdf2q4vH+veqAAAA1Kg5BpMKZkTEV2zf\nJ+kLtj8rUS7BzNbrA/TrrKh22/eK3mHPLh27/4Lnp869c3RzKn7X8GOpeCCLST5FtTIiHrB9oqTP\nSnppba0CekC3JVG9nvACWRu33pqKb8RITS0B9kw/fwqXSjAj4uUtt7dJeoftw2trFQAAQB+LmMEV\nTNt/o90n2H9QbXMAAN0sWyl3cmLN/LlLSsfuHN6Qa8tYbhIOVX7UbWymJpiSVrfcPk/Sx2psC4C9\nwC9DtEP6fZbczjGTNEZjONeW5MLsbP2IOoWkRqcbUaPdJpgRcdn4bdsfbL0PAACAPderM8TLyOzk\n08eXAQBQj1yNptHYVTo2WHcSPa2/d/Jhq0gAAIA2G18Hs19NN8nnKf2scrnA9tbxp9RcG3O/OhsH\nAOgumZ12mvHl17WUpEgsJcTSXOh1M7aCGRH7tqshAIDul++WrnEagwdz8XSpo8vM2AomAAAAqhc9\nvA1kGSSYAIDaRNS5EEs/L/KCmWDGdpEDAACgeiFptI8rmAOdbgAAoHPsgdQx4Nmpw8n/gJkkwqWO\nDNun2L7D9hrbq22fUOI1Z9r+dHF7he1Hi9ffa/ti2+l8kQomAMxkyd1qwsmSC7vnAJOqcSefayRd\nFRFh+6WSLpf0wuQ5LoiITxaJ5bWSTpL0ncwJqGACAAB0QCPKHRkRsS3iP/9SW6gpNsqx/V7b99u+\nSdLxU5xujqR5kp7MtYIKJgAgI7m3OGtPAlNL/HQssr265f7KiFg5VbDtUyX9maTFkn51kueXSjpP\n0islbVGzOnlbS8g5tt8l6TmSvhYRa8o3tYkKJgAAQJs1d/JxqUPSxohY3nJMmVxKUkRcEREvlPQW\nSR+fJOQ4SasiYkNEDEv6woTnL4iIY9RMUBfaPj37/ZFgAsBM5sHk4dwBYEpR8tgd2x8oJuSssX3I\n084fca2k59letEfta26tdbWkE7OvrS3BtP1Z2+tt39Xy2IG2v2n7geLfA4rHX2/7Ftt3Fv++dpLz\nXdV6LgBAFRrJA0AlSo6/nG4MZkRcFBHHFMda20fazb/ubL9C0lxJmya87EZJJ9k+yM39XE+b7NzF\neY6X9GD226uzgvk5SW+c8Ni5kq6JiKPUnOV0bvH4RklvjoijJZ0h6R9aX2T7rZK21dhWAACAthmf\nRV7Dn3Vvk3SX7TWSLpL0Gy2TfppfO2KdpBWSbpB0naR7JpzjnOL1d0kalPSZbCMcNS4JYfsISV+J\niJcU9++TdHJErCsGmK6KiJ+f8BqrmWkvjYhdtvdRszx7lqTLx89V4msHc5gAYPeya08yaQf9YfSW\niFjeyRYcPv/Q+NDzf6dU7B/e/bGOtzer3RnYkiJrlqTHJC2ZJOZtkm6NiF3F/Y9L+itJO9rQPgDo\naQMD85OvyNVHorFr+iAApfTzsq8dm+RTlGufdmltv1jSn0v6neL+MZKeHxFXlDmn7bOK8Z0bqm4v\nAABAVWrsIu8K7a5gPm57aUsX+frxJ2wfJukKSe+JiPHBpL8oabnth4q2Lra9KiJOnuzkxbT9lcX5\n+vjvAqC/0E07NTv3Mb3f/CNS8SONoVT8jqGHU/Ez6f8VkJVdRL2XtLuCeZWak3hU/HulJNneX9JX\nJZ0bEdeNB0fExRFxSEQcIekESfdPlVwCAAD0kiqWKepWtVUwbf+LpJPVXH3+EUkfk3S+pMttv0/S\nw5LeUYSfLelISR+1/dHisTdExHqhp1CJgpR/H2SrdFJyN5no1U4mpXfO2TE8cTWS3Zs1OC8VLw/m\nwpPt7yZ8PqFOzYXWO92K+tSWYEbEb07x1Osmif2EpE9Mc76HJJWaQQ4AANDVor8n+bCODyrFX/zY\nI06O1mmM1tOOQrYCm5X5Ocn+TI2M5OY4joykwrtLdqegfv5tjp7Uw30r0yLBBAAAaDO6yAEgKV3J\nTo7T80Bu3GAkZ0pn2+9kBdYqP46xuYtbfRrJa9NVqEiix/XzO5gEEwAAoM1C0ljUOxynk0gwAQAA\nOoAucgBIyC47NHvWgcn4Ban4oV3rpg9q0chuh5jsqp09e//Ssc/KLpw+tj0Vv2XHfan4nl7yCegy\nJJgAAACoTC8vol4GCSaAyg0MzE3FZyuS2Sra7FkHpOKHR3J7PGTbMzL6ROnYTdtyFcnspCA79//K\nyi0RFclF8eucuMMyaugqQQUTAAAAFevnP3pIMAFULlvRWzB7USr+ie33p+IHkmNCF847IhU/NLwx\nFd9obCsdG42duXMrt+xQelH57OLmWanzZ5eHyr0vGW+KOrEOJgAAACrXx/klCSaA6mWrbtmZz/Pm\n5Gad79j5k1T83MQsb0l6wX5vTMU/2fhp6dj1T92aOnckZ8DnF8Xvpl+JVBjR26hgAgAAoDLNhdY7\n3Yr6kGACqF5ynN4Bc56bih9Vrkq3Y+jhVPz2oR+n4h8c3ZqKP2SfV5aOfd7+ueroT7fdmIofHn48\nFd/PkxKAdqOCCQAAgOpEl404qRgJJgAAQJuF+nsUMQkmgI57fOiuVPw+c5em4ucm43clt5YcHskt\nU/STzd8uHbvfgiNT5z5gfm64wWbnlvoZHtmUis+KyCzMnvz1nCwXMRwAdaOCCQAAgEpRwQSAhOx2\nhaNjuWWNNu/ITcKZO/tZqfjh5MLsESOp+EYifvP2e1LndrLtAwO5bTpnDe6bis8uhl6n0bEtqfjs\nkk9ARigUfVzCJMEEAADoAGaRA0BKrmqVrTBuTy6cnq1czZqVa092S8HRsfLLGkWMJtuSix9LtKUZ\nnwpPS21dmVwOi60f0W36OL8kwQQAAGg39iIHgKSI3Ni17FaR2XGGY8nzj6RmMkvz5jw7FX/AwqNK\nx27e8WDq3COjT6Tie7mq18ttBxTSGGMwAQAAUBUqmACQlfyrfNbAvFT87LkLU/HbdvwwFZ8dx7hz\n+LFU/L7zDi0d+9KFp6bOvcu5GfmPN+5PxT+x/b5UfHaMZ4aTv5xZ1xLdpo8LmCSYAAAAndDo4z96\nSDABAAA6gAomAGQkl48ZGs5ttbhk32NS8U5uh/jUjgdS8dku9Q1bby4du2kgt43mnFkHpOIXzFmU\nis9u07lrdJ9UfCT2Nmk0hlPnHh17KteW5PnpgkdGv+9F3j1bLAAAAMwgEVHq2BO2X2V71PbbS8Se\nafvTxe0Vth+1vcb2vbYvdvavdFHBBFCH5AdidlmjjdvvTcUv2efoVPysgTmp+M3bk5OIGuUn4mSX\nWNo5tiMVP7TrkVR83epcaD39vqQiiTpFfbPIbQ9K+nNJ39jDU1wQEZ8sEstrJZ0k6TuZE1DBBAAA\naLNmF3mUOvbA70v6oqT1UwXYfq/t+23fJOn4KcLmSJon6clsA6hgAqieB3PhyYXTR0Y2pOIf3XJ9\nKv7AfV6Uij/8WSem4p8Yfqh07PaduQpjozGUiu/lWQYstI5eForMQuuLbK9uub8yIlZOFmj7UEmn\nSnqNpFdNEbNU0nmSXilpi5rVydtaQs6x/S5Jz5H0tYhYU7ah46hgAgAAdEBEuUPSxohY3nJMmlwW\nPiXpw7H7v8COk7QqIjZExLCkL0x4/oKIOEbSYkkLbZ+e/d6oYAKoQa6ylJ2tm62QZqt6m7beNn1Q\ni23JmdWHLHhF6dhXzPovqXNnbRrYlIpfO3pnKn7brtwi9KOJMaTZsbtKVjwbMZI7P5BUxTqYtj8g\n6beLu2+StFzS590co7xI0ptsj0bEl7PnjogR21dLOlHS5zOvJcEEAABos+ZWkXufYEbERZIuanno\nueM3bH9O0lcmSS5vlHSh7YMkbZV0mqTbJ57bzSz1eD29+7wUEkwAlbPnpuL3X3hkKn7nyJZU/NDO\nn6bis7OHd+5am4r/8fCU4+6fYf28w1PnPnzesan4Y+fmrv0pBz53+qAWw8lpslsTRcNHtucqmDc1\nvpuK37j11lQ8FU9kdWqlgohYZ3uFpBskbZY0cYzl+BjM2ZLukPSZ7NcgwQQAAOiAuqepRcSZu3nu\nUkmXTvL4Ckkr9vZrk2ACAAC02fgyRf2qIwmm7YckPSVpTNJoRCy3fZqaGfOLJB0bEauL2NdLOl/N\ntZiGJf1RRHy7E+0GUM7AQK6LvO7lZmbPPigVPzKSm/iS7ebKbC25behHqXPfM/TjVPy9yUXl584+\nOBU/a3B+Kn4wsWRV9tybd+SuZXYLUCBnz3fp6QWdrGC+JiJaNyC+S9JbJf3dhLiNkt4cEWttv0TS\n1yUd2qY2AgAA1IIKZhtExD2S5Albf0VE68yluyXNtz030utTAGiXsbFtqfitQw+l4huN3I//rMH9\nUvHz5tb7N+xI4vpkr2V2VFf2Wma3lkxt/SjllqCKsdSp2foR3SQkjSn3Hu4lnVpoPSR9y/Ytts9K\nvO5tkm6dKrm0fZbtB2zntvkAAABoq3LbRPZqlbNTFcwTIuJR24slfdP2vRFx7e5eYPvFam7c/oap\nYoqV7VcW8b35fwToB8nKkpRbOD1rZPSJVPzY2FOp+PnzchXPNy34ndKxr12aGyO5I3np/3H9A6n4\n+5+6OhWfr8ACM0O/T/LpSAUzIh4t/l0v6QpJu124zfZhRdx7IuLB+lsIAABQr0bJ/3pR2yuYthdK\nGoiIp4rbb5D0J7uJ31/SVyWdGxHXtamZAPaGc+PuDt7nxan40eQQ7OzWj9kFs3cMPZyKv3nu90rH\nvnLktalzH/2s3Lab7x88KhW/Ss9Jxf9QuWuzTeVn8G8bzW1DuX1XbvTUyOiTqfjseFbMdKFwbyaP\nZXSigrlE0vds3y7pJklfjYirbZ9q+xFJvyjpq7a/XsSfLelISR+1vaY4Fneg3QAAAJUY7yLv1zGY\n7tc1mJpjMLtmkjwwo+wz/3mp+Mte/I5U/MsW5dapPO3G3HqGazb/Qyo+u15iamZ1shqcrRvMnrV/\nKn7W4IJUfDfZNbI5Fd9IjsVllnovGb0lIpZ3sgULZy2OZfu+vVTs6s0Xd7y9WWRgAAAAbReKHh1f\nWQYJJgAAQJuFpEYfj8EkwQRQuX3nLk3FX7dhdir+0AW5btqvnLQlFf/H3z83FX/55v+bih/atbZ0\nbH67wtwvrOGRjdMHPS0+FQ5gN3p1hngZJJgAAABtFgqNqX/3uyfBBFC5J4d+nIr/5/hWKv7/bMhV\n3U6ae2oq/oTFuYk1H9v/jFT8nU+Ur1p8b2R16txrt+WWZBoZzV3LiP6tuADtFWr08VaRJJgAAAAd\nwCQfAEjYNZxbAHvDaG47wUYjF/+VHX+Riv/3zbkxoQvnH5GK/4U5v1469pcXvCp17rXx0lT8gwO5\navOTYz9NxY82diTjyy8Uv2skN7Z2ZDQXH42duXiWKUJCKJjkAwAAgGrRRQ4AGckNHOzc4uADA/NT\n8WNj21Px2a0in9rxQCr+Wzv+unzwltx4UDtXfc1ey8GBean47P9b17rBXP9Wi9CLWAcTAAAAFQpJ\njaCCCQCleWBOKv7F+56Sit+vsV8q/pZdV6bih3bmxhlmx96l4pPV4IhdqfhGIxffv4uqAO1GBRMA\nAAAVC8ZgAgAAoCostA4ASYMDC1Px6+OHqfitA89KxR8x/9Wp+I1zc0v3DI08kYrfObypdOzo2NbU\nuZUc08XSOkCnhIIxmAAAAKgSe5EDQEJ24PrmoYdT8TuH16bi7bmp+NmzchXS+bMPSMUfum/5xdPn\net/UuYcit5j4UyO5a7kjUX2VpEZi4XRJaiQmKUXU3L2Y3BYz2x6qxzNdMAYTAAAA1QlJkfwjppeQ\nYAKoXHbpm+Hsh2xy6Z5GDKXidw1n43NbY27dUX7M6cBgbjzrgHNLRGUXQs/Knn/Q5Rd+z/5ybmQr\njMn3DZATdJEDAACgQiEm+QBAxoK5S1Pxy+a+PhW/Vvfl4rdcl4rPbhWZlTl/Y3RzjS0B0DkstA4A\nAIAKMQYTAJIOn3dsKv76j+VmGvutZ6Tihz/17FT83119VCr+i4/mqoy3j36jdOy2oYdS545k9bWf\nf8G1m+VUPLPIZzpmkQMAAKBijQY7+QAAAKAi0eezyB3J5T56he0gfwY648B9j07Fn73k1FT8e45c\nl4p/3u/mFk7XIQfn4tduSIWP3l6+/Y98v/yyPZJ024ZFqfg7t+SWNXpwa65Lb8twrkKzo1G+i3+z\nn0qde5MfTcWv27EmFb9reH0qXsnkguEMVRq9JSKWd7IFg4PzY+G855aKfWrHPaXba/tkSVdKGt/z\n9ksR8SfTvOZMScsj4mzbKyT9tqQNkuZJ+o6kD0TyDUgGBgAA0G5R617k/xERv7YXr78gIj7p5kK2\n10o6Sc1EszQSTACVGxnbmYq/ZOOqVPwnHrwhFT/wrdxi5c/e55hU/DHOTWp69eLnlW/LvFzVaqSR\nm2iSPf9Bc3LnbyhXIY0oH795ZJ/UuW/deGAqfsucn6bih4dzlex+7UFEeZ1cpsj2eyV9RNJmSbdL\nmmyHjDmye3qDAAAJ8klEQVRqVjGfzJ6/3i0cAAAAMIlQRKPUsQdebfsO21+z/eKJT9peKuk8ScdL\nOkHSsgkh59heI2mdpPsjIjdeRFQwAZSUWYJl4ezcOMCs7NIeo8nFyh/ZvCoXr1z8V9K1gPKyS+XI\nyfhkXcIerPX8GdklnJTsvmTZIWQk18FcZHt1y/2VEbFyithbJR0eEdtsv0nSlyVNXHvtOEmrImKD\nJNn+gqQXtDw/3kU+W9K/2T49Ij5ftrESFUwAAICOCDVKHZI2RsTyluM/k0vbH7C9pjgOiYitEbFN\nkiLi3yXNtr1Hf/VH86+yqyWdmH0tFUwA5SQqUa/wCalT7zt7dir+xv1zM6vXbrstFT86misxZiuq\ndc4GTlfR0uMAszOf+3edv4lYaB05UclnQURcJOmi8fu2ny3p8YgI28eqWUzcNOFlN0q60PZBkrZK\nOk3NcZhPY9tqdqPnPkRFggkAANABUdcfYG+X9Hu2RyUNSTo9Jswoi4h1xXJEN6g5yWfiGMtzbL9L\n0mxJd0j6TLYRrIMJoBS7/M/TBS/6SOrcZ1//8lxj9t03FT5w5dWp+Cf/7bFU/C0/WpqK/97GBaVj\nf7ItV+HYOpL7hbV9LLlOZUw20XRqI86Ne2wkqnoDyYrhYOR+J8xO/g6Zm/gZkaTb4j9S8Ru23pKK\nn0nV47zOr4M54Nkxa1a5lQ1GRtd3vL1ZZGAAAABtFursMkV1I8EEAABou2rGYHYrEkygT6SXp0kr\n/0H4qXU3pc58/0tyLXlObn1tLdsvt1TOwfNyEy4PmpfrNv61Q4ZLx+4cyy7zkzN7IPcLbjC5rNGA\ncxO4MqcfdK7tQ6O5a7luaG4q/vubcovKr938gumDWjwxeF8qPrs8Fzqhtp18Oo4EEwAAoO36u4LJ\nJB+gTWqvMNa9YHai/XVPLui25V3qXNzcSlYwkxNNnKwwDg7kqnT5hdnLx2diJanRKF85lqSxxlDy\n/LlKdnbJp+ySUt32c1Kn/BJRIx2fNGMPxsBAuSXXGo3tHW9vFhkYAABA24XUxxXMnkkwbb9R0oWS\nBiVdEhHnd7hJQEq2mpCuimV7I5Lj1yJTiUpXU5O6rOelzsXN07NMs9shKlelG+vfIWPoIvWPKe8O\n/Vxl7okE083NbC+S9HpJj0i62fZVEfGDzrYMAABgDyX3u+8lPZFgSjpW0g8j4keSZPvzkk6RtJsE\n06XH5/TyINs6x37tmeT29skfrjr/2uu6bd4SWzPuiYGB3AzZAZePzyzK3ozPvW/GGjtz8WNbU/Fp\nXTQ2ru7KTzdVXLrt8y/7u6T29mfel+nPm3rHj84M0VU/T1XrlQTzUEk/bbn/iKTjJgbZPkvSH0na\nX9JIxPAd7Wle56TfmlO/YJGkjXvTll63Bz/mtV6zuifKjI0lk7S9/5Iz/j22B9LXrH9/XT3TFN/r\n1Nesyy5OhZ/fe6N5vdJDK3reczrdAElfl0bLronWc5+dvZJglhIRKyWtlCTbq3ttxlUncb3yuGY5\nXK88rlke1yyH69U5EfHGTrehTsn+zI55VNLPtdw/rHgMAAAAXaZXEsybJR1l+7m250g6XdJVHW4T\nAAAAJtETXeQRMWr7bElfV3OZos9GxN3TvGxl/S3rK1yvPK5ZDtcrj2uWxzXL4XqhFn27kw8AAAA6\no1e6yAEAANAjSDABAABQqb5LMG2/0fZ9tn9o+9xOt6cbTHdNbL/Q9g22d9n+0ITnHrJ9p+01tle3\nr9XdocS1O8X2HePXx/YJnWhnp5X9ubP9Ktujtt/e8tiMfo9J5a6f7ZOLa3S37e+2u42dVuJn8Y+K\n67PG9l22x2wfWDzHe2z663eA7SuKz7ObbL+kE+1EH4mIvjnUnAD0oKTnSZoj6XZJyzrdrm6/JpIW\nS3qVpD+V9KEJzz0kaVGnv48uvnb76GdjmV8q6d5Ot7sbr1NL3Lcl/bukt7c8PmPfY2Wvn5qbR/xA\n0uHF/cWdbne3XaMJ8W+W9O2W+7zHpn+P/aWkjxW3Xyjpmk63m6O3j36rYP7nlpIRMSxpfEvJmWza\naxIR6yPiZkkzbiuHaZS5dtsiYnym3EJ13V4hbVH25+73JX1R0vp2Nq4HlLl+/1XSlyLiJ1LzZ7bN\nbey07Gf7b0r6l7a0rDeUuX7L1PwDUBFxr6QjbC9pbzPRT/otwZxsS8lDO9SWbrG31yQkfcv2LcVW\nnDNJqWtn+1Tb90r6qqTfalPbusm018n2oZJOlXTxJK+fye8xqdz77AWSDrC9qrhO72lb67pD6c8x\n2wskvVHNP2bG8R6b/vrdLumtkmT7WDW3UjysLa1DX+qJdTDRUSdExKO2F0v6pu17I+LaTjeqm0TE\nFZKusH2ipI9L+uUON6kbfUrShyOiYXvic7zHpjdL0islvU7SfEk32P5+RNzf2WZ1pTdLui4inmh5\njPfY9M6XdKHtNZLulHSbpLHONgm9rN8STLaUfKa9uiYR8Wjx73rbV6jZ1TJTPphT1y4irrX9PNuL\nImJj7a3rHmWu03JJny+Sy0WS3mR7NCK+PMPfY1K56/eIpE0RsV3SdtvXSnqZpJmSYGZ+Fk/XhO5x\n3mPTX7+I2CrpvZLk5g/qjyX9qF0NRP/pty5ytpR8pj2+JrYX2t53/LakN0i6q7aWdp9pr53tI4sP\nY9l+haS5kja1vaWdNe11iojnRsQREXGEpH+T9N8i4su8xySV+xm9UtIJtmcVXcDHSbqnze3spFKf\nY7afJekkNa/X+GO8x8p9lu1fPCdJ75d0bZF0AnukryqYsWdbSva1qa6J7d8tnv9b28+WtFrSfpIa\ntj+o5oDvRWp2/UrN98o/R8TVnfg+OqHMtZP0NknvsT0iaUjSb7RM+pkRSl6nqSzRDH6PSeWuX0Tc\nY/tqSXdIaki6JCJmTJKUeI+dKukbRaV3HO+xctfvRZIusx2S7pb0vo41GH2BrSIBAABQqX7rIgcA\nAECHkWACAACgUiSYAAAAqBQJJgAAACpFggkAAIBK9dUyRQBmBtsHSbqmuPtsNXcc2VDc3xERr+5I\nwwAAklimCECPs71C0raI+GSn2wIAaKKLHEBfsb2t+Pdk29+1faXtH9k+3/Y7bd9k+07bzy/iDrb9\nRds3F8fxnf0OAKD3kWAC6Gcvk/S7au5S8m5JL4iIYyVdIun3i5gLJV0QEa9Sc2emSzrRUADoJ4zB\nBNDPbo6IdZJk+0FJ3ygev1PSa4rbvyxpWbGVoCTtZ3ufiNjW1pYCQB8hwQTQz3a13G603G/oZ59/\nA5J+ISJ2trNhANDP6CIHMNN9Qz/rLpftYzrYFgDoCySYAGa6P5C03PYdtn+g5phNAMBeYJkiAAAA\nVIoKJgAAACpFggkAAIBKkWACAACgUiSYAAAAqBQJJgAAACpFggkAAIBKkWACAACgUv8fPby/AHAV\ncooAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ededd73dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1edefc56b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def gen_image(arr):\n",
    "    two_d = (np.reshape(arr, (28, 28)) * 255).astype(np.uint8)\n",
    "    plt.imshow(two_d, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "def plotNormalizedSpectrogram(normalizedSpecto):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    spectrogramData = normalizedSpecto\n",
    "    librosa.display.specshow(librosa.power_to_db(spectrogramData, ref=np.max), y_axis='mel', fmax=8000, x_axis='time')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plotDescription(dispText):\n",
    "    plt.figure()    \n",
    "    ax = plt.subplot(111)\n",
    "    textArr = dispText.split(' ')\n",
    "    lenTextMid = int(len(textArr) / 2)\n",
    "    t = plt.text(0.05, 0.6, ' '.join(textArr[0:lenTextMid]), transform=ax.transAxes, fontsize=25)\n",
    "    t = plt.text(0.05, 0.3, ' '.join(textArr[lenTextMid:lenTextMid*2]), transform=ax.transAxes, fontsize=25)\n",
    "    plt.show()    \n",
    "    \n",
    "def displaySample(predict, dataSet, wrongPred):\n",
    "    \n",
    "    n = wrongPred[0]\n",
    "    gn_predict = wrongPred[1]\n",
    "\n",
    "    AC_predict = np.argmax(predict[n][0])\n",
    "    IC_predict = np.argmax(predict[n][1])\n",
    "    TC_predict = np.argmax(predict[n][2])\n",
    "\n",
    "    \n",
    "    audio = np.reshape(dataSet[0][n], [128,44 ])\n",
    "    image = dataSet[1][n]\n",
    "    text = dataSet[2][n]\n",
    "    real_label = dataSet[4][n]\n",
    "\n",
    "    print(\"Showing sample number\",n)\n",
    "    print(\"Prediction - GN\",gn_predict,\"AC\",AC_predict, \"IC\",IC_predict, \"TC\",TC_predict)\n",
    "    print(\"Real label\",real_label)\n",
    "    digImg = gen_image(image)\n",
    "    plotNormalizedSpectrogram(audio)\n",
    "    plotDescription(text)\n",
    "\n",
    "_, validationSet = loadData_ThreeModal(\"0.9\",\"0.9\",\"0.9\")\n",
    "    \n",
    "\n",
    "correct_index = correct_samples[70] \n",
    "incorrect_index = incorrect_samples[17] # 0, 13, 17, 24\n",
    "\n",
    "#displaySample(validationSet,Display_Validation_Data,correct_index)\n",
    "displaySample(validationSet,Display_Validation_Data,incorrect_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "13\n",
      "17\n",
      "24\n",
      "No one correct 4 ( 13.333333 of all incorrect samples)\n",
      "GN had 0 when all AC/IC/TC were incorrect but 0 wrong when AC/IC/TC were correct\n",
      "AC had 24 IC had 2 wrong and TC had 2 wrong\n"
     ]
    }
   ],
   "source": [
    "AC_wrong, IC_wrong, TC_wrong, GN_wrong, GN_right = 0,0,0,0,0\n",
    "c = 0\n",
    "for i in range(len(incorrect_samples)):\n",
    "    nsample = incorrect_samples[i][0] # index, 1 is gn prediction\n",
    "    gn_predict = incorrect_samples[i][1] \n",
    "    \n",
    "    correct_label = np.argmax(validationSet[nsample][3])\n",
    "    AC_predict = np.argmax(validationSet[nsample][0])\n",
    "    IC_predict = np.argmax(validationSet[nsample][1])\n",
    "    TC_predict = np.argmax(validationSet[nsample][1])\n",
    "    \n",
    "    if(AC_predict != correct_label and IC_predict != correct_label and TC_predict != correct_label):\n",
    "        c += 1 #print(nsample)\n",
    "        print(i)\n",
    "    else:\n",
    "        if (AC_predict != correct_label):\n",
    "            AC_wrong += 1\n",
    "        if (IC_predict != correct_label):\n",
    "            IC_wrong += 1\n",
    "        if (TC_predict != correct_label):\n",
    "            TC_wrong += 1\n",
    "    \n",
    "    if(AC_predict == correct_label and IC_predict == correct_label and TC_predict == correct_label):\n",
    "        GN_wrong += 1\n",
    "        \n",
    "for i in range(len(correct_samples)):\n",
    "    nsample = correct_samples[i][0] # index, 1 is gn prediction\n",
    "    gn_predict = correct_samples[i][1] \n",
    "    \n",
    "    correct_label = np.argmax(validationSet[nsample][2])\n",
    "    AC_predict = np.argmax(validationSet[nsample][0])\n",
    "    IC_predict = np.argmax(validationSet[nsample][1])\n",
    "    \n",
    "    if(AC_predict != correct_label and IC_predict != correct_label and TC_predict == correct_label):\n",
    "        if(gn_predict == correct_label):\n",
    "            GN_right += 1\n",
    "\n",
    "print(\"No one correct\",c, \"(\",\"{:2f}\".format((c/len(incorrect_samples))*100),\"of all incorrect samples)\") \n",
    "print(\"GN had\",GN_right,\"when all AC/IC/TC were incorrect but\",GN_wrong,\"wrong when AC/IC/TC were correct\")\n",
    "print(\"AC had\",AC_wrong, \"IC had\",IC_wrong,\"wrong and TC had\" , TC_wrong,\"wrong\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validHold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-2ef7954fbef2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m \u001b[0mplotROC_Curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidHold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_10_svc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'validHold' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "### https://hackernoon.com/simple-guide-on-how-to-generate-roc-plot-for-keras-classifier-2ecc6c73115a\n",
    "### SKOÐA Macro based for multiclass\n",
    "\n",
    "def plotROC_Curve(ground_truth, prediction, zoom_range):\n",
    "    lw = 2\n",
    "    \n",
    "    y_score = np.eye(10)[[row[5] for row in ground_truth]]\n",
    "    y_test = np.eye(10)[[row for row in prediction]]\n",
    "\n",
    "    \n",
    "    n_classes = len(y_test[0])\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_test.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # Compute macro-average ROC curve and ROC area\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    # Zoom in view of the upper left corner.\n",
    "    plt.figure(2)\n",
    "    plt.xlim(0, zoom_range)\n",
    "    plt.ylim(1-zoom_range, 1)\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label='micro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"micro\"]),\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "             label='macro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"macro\"]),\n",
    "             color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "    \"\"\"colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                 ''.format(i, roc_auc[i]))\n",
    "    \"\"\"\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "plotROC_Curve(validHold, y_pred_10_svc, 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ENSEMBLE\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "#import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### helper function ###\n",
    "def print_score(clf, X_train, y_train, X_test, y_test):\n",
    "    '''\n",
    "    print the accuracy score, classification report and confusion matrix of classifier\n",
    "    '''\n",
    "    if train:\n",
    "        print(\"Test Result:\\n\")        \n",
    "        print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_test, clf.predict(X_test))))\n",
    "        print(\"Classification Report: \\n {}\\n\".format(classification_report(y_test, clf.predict(X_test))))\n",
    "        print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_test, clf.predict(X_test))))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
